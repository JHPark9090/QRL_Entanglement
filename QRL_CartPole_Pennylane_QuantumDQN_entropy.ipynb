{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69745fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n",
      "Running on the GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available and if so, which device is being used\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "    device = torch.device('cuda')  # Set the device to GPU\n",
    "    print('Running on the GPU:', torch.cuda.get_device_name())\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "    device = torch.device('cpu')  # Set the device to CPU\n",
    "    print('Running on the CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a15fb06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'CartPole-v1'\n",
    "\n",
    "import gymnasium as gym\n",
    "import tianshou as ts\n",
    "import numpy as np\n",
    "\n",
    "from tianshou.policy import DQNPolicy, QRDQNPolicy, C51Policy, RainbowPolicy\n",
    "from tianshou.env import DummyVectorEnv\n",
    "from tianshou.data import Collector, VectorReplayBuffer, PrioritizedVectorReplayBuffer\n",
    "from tianshou.trainer import offpolicy_trainer\n",
    "from tianshou.utils.net.discrete import NoisyLinear\n",
    "\n",
    "env = gym.make(env_name)\n",
    "\n",
    "train_envs = ts.env.DummyVectorEnv([lambda: gym.make(env_name) for _ in range(10)])\n",
    "test_envs = ts.env.DummyVectorEnv([lambda: gym.make(env_name) for _ in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35aded22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from datetime import datetime\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import pennylane as qml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af088bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(n_qubits, inputs):\n",
    "    for wire in range(n_qubits):\n",
    "        qml.RX(inputs[wire], wires=wire)\n",
    "\n",
    "\n",
    "def layer(n_qubits, y_weight, z_weight):\n",
    "    for wire, y_weight in enumerate(y_weight):\n",
    "        qml.RY(y_weight, wires=wire)\n",
    "    for wire, z_weight in enumerate(z_weight):\n",
    "        qml.RZ(z_weight, wires=wire)\n",
    "    for wire in range(n_qubits):\n",
    "        qml.CZ(wires=[wire, (wire + 1) % n_qubits])\n",
    "\n",
    "\n",
    "def measure(n_qubits):\n",
    "    return [\n",
    "        qml.expval(qml.PauliZ(0) @ qml.PauliZ(1)),\n",
    "        qml.expval(qml.PauliZ(2) @ qml.PauliZ(3))\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_model(n_qubits, n_layers, data_reupload, return_val=True):\n",
    "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "    shapes = {\n",
    "        \"y_weights\": (n_layers, n_qubits),\n",
    "        \"z_weights\": (n_layers, n_qubits)\n",
    "    }\n",
    "\n",
    "    @qml.qnode(dev, interface='torch')\n",
    "    def circuit(inputs, y_weights, z_weights):\n",
    "        for layer_idx in range(n_layers):\n",
    "            if (layer_idx == 0) or data_reupload:\n",
    "                encode(n_qubits, inputs)\n",
    "            layer(n_qubits, y_weights[layer_idx], z_weights[layer_idx])\n",
    "        if return_val:\n",
    "            return measure(n_qubits)\n",
    "        else:\n",
    "            return qml.vn_entropy(wires=[0])\n",
    "    \n",
    "    model = qml.qnn.TorchLayer(circuit, shapes)    \n",
    "    return model \n",
    "\n",
    "entropy_out = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "274ec2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumDQN(nn.Module):\n",
    "    def __init__(self, n_qubits, n_actions, n_layers, w_input, w_output, data_reupload):\n",
    "        super(QuantumDQN, self).__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_actions = n_actions\n",
    "        self.n_layers = n_layers\n",
    "        self.w_input = w_input\n",
    "        self.w_output = w_output\n",
    "        self.data_reupload = data_reupload\n",
    "        self.q_layers = get_model(n_qubits=self.n_qubits,\n",
    "                                  n_layers=n_layers,\n",
    "                                  data_reupload=data_reupload,\n",
    "                                  return_val=True)\n",
    "        self.entropy = get_model(n_qubits=self.n_qubits,\n",
    "                                  n_layers=n_layers,\n",
    "                                  data_reupload=data_reupload,\n",
    "                                  return_val=False)\n",
    "        if w_input:\n",
    "            self.w_input2 = Parameter(torch.Tensor(self.n_qubits))\n",
    "            nn.init.normal_(self.w_input2, mean=0.)\n",
    "        else:\n",
    "            self.register_parameter('w_input', None)\n",
    "        if w_output:\n",
    "            self.w_output2 = Parameter(torch.Tensor(self.n_actions))\n",
    "            nn.init.normal_(self.w_output2, mean=90.)\n",
    "        else:\n",
    "            self.register_parameter('w_output', None)\n",
    "\n",
    "    def forward(self, inputs, **kwargs):\n",
    "      batch_size = inputs.shape[0]  # Get the batch size\n",
    "      outputs = []\n",
    "      entropy = []\n",
    "    \n",
    "      for i in range(batch_size):\n",
    "        input_i = inputs[i]  # Get the i-th input in the batch\n",
    "        input_i = torch.tensor(input_i, dtype=torch.float32)  # Convert input_i to a PyTorch tensor\n",
    "        if self.w_input2 is not None:\n",
    "            input_i = input_i * self.w_input2\n",
    "        input_i = torch.atan(input_i)\n",
    "        output_i = self.q_layers(input_i)\n",
    "        entropy_i = self.entropy(input_i)\n",
    "        output_i = (1 + output_i) / 2\n",
    "        outputs.append(output_i)\n",
    "        entropy.append(entropy_i)\n",
    "\n",
    "      outputs = torch.stack(outputs)  # Stack outputs along the batch dimension\n",
    "      # entropy_out = torch.stack(entropy)\n",
    "      entropy_out.append(entropy)\n",
    "\n",
    "      if self.w_output2 is not None:\n",
    "        outputs = outputs * self.w_output2\n",
    "      else:\n",
    "        outputs = 90 * outputs\n",
    "        outputs = outputs.view(-1, self.n_qubits * 2)\n",
    "\n",
    "      return outputs, None\n",
    "\n",
    "    def __deepcopy__(self, memodict={}):\n",
    "        # Target Network: Create a new instance of the class\n",
    "        new_instance = QuantumDQN(n_qubits = self.n_qubits,\n",
    "                                      n_actions = self.n_actions,\n",
    "                                      n_layers = self.n_layers,\n",
    "                                      w_input = self.w_input,\n",
    "                                      w_output = self.w_output,\n",
    "                                      data_reupload = self.data_reupload)\n",
    "\n",
    "        # Assign the quantum parts after copying\n",
    "        new_instance.q_layers = copy.deepcopy(self.q_layers, memodict)\n",
    "        new_instance.entropy = copy.deepcopy(self.entropy, memodict)\n",
    "\n",
    "        return new_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e27838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your defined network\n",
    "state_shape = env.observation_space.shape[0]  # equivalent to 4 for CartPole-v1\n",
    "action_shape = env.action_space.n  # equivalent to 2 for CartPole-v1\n",
    "\n",
    "net = QuantumDQN(n_qubits=state_shape, n_actions=action_shape, n_layers=3, w_input=True, w_output=True, \n",
    "                     data_reupload=True)\n",
    "# net = net.to(args.device)\n",
    "\n",
    "optim = torch.optim.RMSprop(net.parameters(), lr=0.001)\n",
    "policy = DQNPolicy(net, optim, discount_factor=0.99,\n",
    "                       estimation_step=5,\n",
    "                       target_update_freq=320, is_double=False)\n",
    "# policy = policy.to(args.device)\n",
    "\n",
    "buffer = VectorReplayBuffer(total_size=20000, buffer_num=10)  # max size of the replay buffer\n",
    "train_collector = Collector(policy, train_envs, buffer, exploration_noise=True)\n",
    "test_collector = Collector(policy, test_envs, exploration_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b582b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 1001it [14:41,  1.14it/s, env_step=1000, len=10, loss=1139.431, n/ep=2, n/st=10, rew=10.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: 9.592000 ± 0.988704, best_reward: 9.657000 ± 1.060826 in #0\n",
      "Finished training! Use 1620.69s\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tianshou.utils import TensorboardLogger\n",
    "writer = SummaryWriter(f'log/CartPole_Quantum_DQN')\n",
    "logger = TensorboardLogger(writer)\n",
    "\n",
    "# Start training\n",
    "result = offpolicy_trainer(\n",
    "    policy,\n",
    "    train_collector,\n",
    "    test_collector,\n",
    "    max_epoch=1,  # maximum number of epochs\n",
    "    step_per_epoch=1000,  # number of steps per epoch\n",
    "    step_per_collect=10,  # number of steps per data collection\n",
    "    update_per_step=0.1,\n",
    "    episode_per_test=1000,  # number of episodes per test\n",
    "    batch_size=64,  # batch size for updating model\n",
    "    train_fn=lambda epoch, env_step: policy.set_eps(0.1),\n",
    "    test_fn=lambda epoch, env_step: policy.set_eps(0.05),\n",
    "    stop_fn=lambda mean_rewards: mean_rewards >= env.spec.reward_threshold,\n",
    "    logger=logger)\n",
    "\n",
    "print(f'Finished training! Use {result[\"duration\"]}')"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2d2125bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0       1       2       3       4       5       6       7       8    \\\n",
      "0   0.6693  0.6675  0.6663  0.6656  0.6651  0.6642  0.6628  0.6607  0.6582   \n",
      "1   0.6723  0.6703  0.6719  0.6699  0.6686  0.6679  0.6673  0.6664  0.6649   \n",
      "2   0.6723  0.6702  0.6690  0.6683  0.6677  0.6667  0.6651  0.6629  0.6603   \n",
      "3   0.6697  0.6677  0.6665  0.6658  0.6652  0.6642  0.6627  0.6605  0.6579   \n",
      "4   0.6738  0.6719  0.6708  0.6703  0.6697  0.6687  0.6671  0.6648  0.6751   \n",
      "..     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "95  0.6718  0.6699  0.6688  0.6681  0.6675  0.6665  0.6649  0.6627  0.6711   \n",
      "96  0.6685  0.6666  0.6654  0.6647  0.6641  0.6632  0.6617  0.6595  0.6570   \n",
      "97  0.6751  0.6732  0.6721  0.6715  0.6710  0.6703  0.6688  0.6667  0.6641   \n",
      "98  0.6738  0.6720  0.6708  0.6702  0.6698  0.6690  0.6677  0.6657  0.6631   \n",
      "99  0.6720  0.6698  0.6685  0.6678  0.6672  0.6662  0.6646  0.6624  0.6700   \n",
      "\n",
      "       9    ...     595     596     597     598     599     600     601  \\\n",
      "0   0.6555  ...  0.6746  0.6760  0.6764  0.6757  0.6741  0.6721  0.6700   \n",
      "1   0.6627  ...  0.6755  0.6747  0.6731  0.6712  0.6684  0.6720  0.6700   \n",
      "2   0.6740  ...  0.6713  0.6737  0.6720  0.6701  0.6684  0.6687  0.6711   \n",
      "3   0.6721  ...  0.6749  0.6713  0.6711  0.6698  0.6739  0.6685  0.6725   \n",
      "4   0.6732  ...  0.6729  0.6717  0.6698  0.6680  0.6703  0.6726  0.6712   \n",
      "..     ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "95  0.6693  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "96  0.6543  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "97  0.6708  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "98  0.6602  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "99  0.6679  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "       602     603     604  \n",
      "0   0.6695  0.6686  0.6697  \n",
      "1   0.6705  0.6684     NaN  \n",
      "2   0.6694  0.6715     NaN  \n",
      "3   0.6692     NaN     NaN  \n",
      "4   0.6702     NaN     NaN  \n",
      "..     ...     ...     ...  \n",
      "95     NaN     NaN     NaN  \n",
      "96     NaN     NaN     NaN  \n",
      "97     NaN     NaN     NaN  \n",
      "98     NaN     NaN     NaN  \n",
      "99     NaN     NaN     NaN  \n",
      "\n",
      "[100 rows x 605 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "numbers = [[float(re.search(r'\\d+\\.\\d+', str(value)).group()) for value in sublist] for sublist in entropy_out]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(numbers)\n",
    "# Transpose the DataFrame to have the inner lists as columns\n",
    "df = df.transpose()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db1dbb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08233635023100414"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qml.math.vn_entropy([0.4781+0.j, 0.4778+0.j, 0.4782+0.j, 0.4778+0.j], indices=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4a56498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08233635023100414"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qml.math.vn_entropy([0.4781+0.j, 0.4778+0.j, 0.4782+0.j, 0.4778+0.j], indices=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dad0caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08198868931856183"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qml.math.vn_entropy([0.4781+0.j, 0.4778+0.j, 0.4782+0.j, 0.4782+0.j], indices=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3f9530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# file_path = f'/scratch/connectome/justin/log_0/PennyLane_CartPole_Quantum_DQN_entropy_00.csv'\n",
    "# with open(file_path, mode='w', newline='') as file:\n",
    "#     csv_writer = csv.writer(file)\n",
    "v    csv_writer.writerow(entropy_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290b150f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
