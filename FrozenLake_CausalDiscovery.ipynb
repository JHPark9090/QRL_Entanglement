{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fead8b5d",
   "metadata": {},
   "source": [
    "# FrozenLake: DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93642db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log_Negativity</th>\n",
       "      <th>Coherent_Information</th>\n",
       "      <th>Entangling_Capability</th>\n",
       "      <th>Effective_Dimension</th>\n",
       "      <th>Expressibility</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.197286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>9.210000e-17</td>\n",
       "      <td>1.206565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.116226</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>4.440000e-17</td>\n",
       "      <td>1.210094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.031595</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>4.510000e-17</td>\n",
       "      <td>1.210114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.911391</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>5.290000e-17</td>\n",
       "      <td>1.212265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.799224</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Log_Negativity  Coherent_Information  Entangling_Capability  \\\n",
       "0    3.970000e-08          0.000000e+00               1.197286   \n",
       "1    3.970000e-08          9.210000e-17               1.206565   \n",
       "2    3.970000e-08          4.440000e-17               1.210094   \n",
       "3    3.970000e-08          4.510000e-17               1.210114   \n",
       "4    3.970000e-08          5.290000e-17               1.212265   \n",
       "\n",
       "   Effective_Dimension  Expressibility  Performance  \n",
       "0                  NaN             NaN         0.11  \n",
       "1                  NaN       29.116226         0.11  \n",
       "2                  NaN       19.031595         0.16  \n",
       "3                  NaN       17.911391         0.09  \n",
       "4                  NaN       17.799224         0.17  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "filename= 'PennyLane_FrozenLake-v1_Quantum_DQN_all.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "df = df.drop([\"Unnamed: 0\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70284840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of observations to downsample to\n",
    "target_obs = df['Performance'].count()\n",
    "\n",
    "# Initialize a dictionary to hold downsampled DataFrames\n",
    "downsampled_columns = {}\n",
    "\n",
    "# List of columns to downsample\n",
    "columns_to_downsample = [\"Log_Negativity\", \"Coherent_Information\", \"Entangling_Capability\", \"Effective_Dimension\", \"Expressibility\"]\n",
    "\n",
    "# Loop through each column, downsample, and store in the dictionary\n",
    "for column in columns_to_downsample:\n",
    "    # Ensure column has enough observations for downsampling\n",
    "    if len(df[column].dropna()) >= target_obs:\n",
    "        downsampled_columns[column] = df[[column]].dropna().sample(n=target_obs, random_state=42).reset_index(drop=True)\n",
    "    else:\n",
    "        print(f\"Column {column} does not have enough observations to downsample to {target_obs}.\")\n",
    "\n",
    "# Add the Performance column to the dictionary as is, assuming it already has the correct number of observations\n",
    "downsampled_columns[\"Performance\"] = df[[\"Performance\"]].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b8ebf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log_Negativity</th>\n",
       "      <th>Coherent_Information</th>\n",
       "      <th>Entangling_Capability</th>\n",
       "      <th>Effective_Dimension</th>\n",
       "      <th>Expressibility</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.880000e-07</td>\n",
       "      <td>1.370000e-16</td>\n",
       "      <td>1.825648</td>\n",
       "      <td>3.208989</td>\n",
       "      <td>212.264957</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.360000e-08</td>\n",
       "      <td>1.000000e-16</td>\n",
       "      <td>1.984263</td>\n",
       "      <td>3.003928</td>\n",
       "      <td>64.976044</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.030000e-07</td>\n",
       "      <td>3.470000e-17</td>\n",
       "      <td>1.953761</td>\n",
       "      <td>2.828152</td>\n",
       "      <td>192.080031</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.840000e-07</td>\n",
       "      <td>6.560000e-17</td>\n",
       "      <td>1.929794</td>\n",
       "      <td>3.120558</td>\n",
       "      <td>22.967222</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.710000e-07</td>\n",
       "      <td>6.110000e-17</td>\n",
       "      <td>1.890436</td>\n",
       "      <td>3.012406</td>\n",
       "      <td>258.712843</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>-1.540000e-07</td>\n",
       "      <td>-5.460000e-17</td>\n",
       "      <td>1.928911</td>\n",
       "      <td>3.206531</td>\n",
       "      <td>153.346907</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>-3.650000e-08</td>\n",
       "      <td>-1.480000e-16</td>\n",
       "      <td>1.454425</td>\n",
       "      <td>3.108432</td>\n",
       "      <td>28.558819</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>1.150000e-07</td>\n",
       "      <td>-5.460000e-16</td>\n",
       "      <td>1.985571</td>\n",
       "      <td>3.178955</td>\n",
       "      <td>122.004727</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>-2.890000e-07</td>\n",
       "      <td>6.170000e-17</td>\n",
       "      <td>1.501376</td>\n",
       "      <td>3.142971</td>\n",
       "      <td>114.401690</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>1.080000e-07</td>\n",
       "      <td>-3.120000e-17</td>\n",
       "      <td>1.977693</td>\n",
       "      <td>2.784502</td>\n",
       "      <td>257.967762</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>533 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Log_Negativity  Coherent_Information  Entangling_Capability  \\\n",
       "0     -1.880000e-07          1.370000e-16               1.825648   \n",
       "1     -9.360000e-08          1.000000e-16               1.984263   \n",
       "2      1.030000e-07          3.470000e-17               1.953761   \n",
       "3     -1.840000e-07          6.560000e-17               1.929794   \n",
       "4     -1.710000e-07          6.110000e-17               1.890436   \n",
       "..              ...                   ...                    ...   \n",
       "528   -1.540000e-07         -5.460000e-17               1.928911   \n",
       "529   -3.650000e-08         -1.480000e-16               1.454425   \n",
       "530    1.150000e-07         -5.460000e-16               1.985571   \n",
       "531   -2.890000e-07          6.170000e-17               1.501376   \n",
       "532    1.080000e-07         -3.120000e-17               1.977693   \n",
       "\n",
       "     Effective_Dimension  Expressibility  Performance  \n",
       "0               3.208989      212.264957         0.11  \n",
       "1               3.003928       64.976044         0.11  \n",
       "2               2.828152      192.080031         0.16  \n",
       "3               3.120558       22.967222         0.09  \n",
       "4               3.012406      258.712843         0.17  \n",
       "..                   ...             ...          ...  \n",
       "528             3.206531      153.346907         0.00  \n",
       "529             3.108432       28.558819         0.00  \n",
       "530             3.178955      122.004727         0.00  \n",
       "531             3.142971      114.401690         0.00  \n",
       "532             2.784502      257.967762         0.00  \n",
       "\n",
       "[533 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all downsampled columns into one DataFrame\n",
    "# Since they are independent and have been reset index, we can simply concatenate them side by side\n",
    "data = pd.concat(downsampled_columns.values(), axis=1)\n",
    "\n",
    "# Renaming columns to ensure they retain their original names\n",
    "data.columns = downsampled_columns.keys()\n",
    "\n",
    "# Now, downsampled_df is a single DataFrame containing all the downsampled columns\n",
    "# You can inspect the first few rows to verify\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cc70617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting 7 CUDA device(s).\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "import cdt\n",
    "# from cdt import SETTINGS\n",
    "# SETTINGS.verbose=False\n",
    "# SETTINGS.NJOBS=16\n",
    "import networkx as nx\n",
    "import time\n",
    "\n",
    "# A warning on R libraries might occur. It is for the use of the r libraries that could be imported into the framework\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4345c852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (2.1.0)\n",
      "Collecting torch\n",
      "  Using cached torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Using cached typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Collecting triton==2.2.0 (from torch)\n",
      "  Using cached triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.52)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/755.5 MB\u001b[0m \u001b[31m108.6 kB/s\u001b[0m eta \u001b[36m1:53:56\u001b[0m^C\n",
      "\u001b[2K   \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/755.5 MB\u001b[0m \u001b[31m108.2 kB/s\u001b[0m eta \u001b[36m1:54:21\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd7619cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Finding the structure of the graph\n",
    "# from cdt.independence.graph import FSGNN\n",
    "\n",
    "# obj = FSGNN()\n",
    "\n",
    "# start_time = time.time()\n",
    "# ugraph = obj.predict(data)\n",
    "# print(\"--- Execution time : %4.4s seconds ---\" % (time.time() - start_time))\n",
    "# nx.draw_networkx(ugraph, font_size=8) # The plot function allows for quick visualization of the graph.\n",
    "# plt.show()\n",
    "# # List results\n",
    "# pd.DataFrame(list(ugraph.edges(data='weight')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59335510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d9a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b5a99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb9e9f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "graphical_lasso: did not converge after 2000 iteration: dual gap: -2.826e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cause</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Log_Negativity</td>\n",
       "      <td>Log_Negativity</td>\n",
       "      <td>1.549492e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coherent_Information</td>\n",
       "      <td>Coherent_Information</td>\n",
       "      <td>5.482663e+31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>2.108352e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>1.504357e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>4.910030e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>3.562931e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>1.504357e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>3.562931e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>1.502563e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Performance</td>\n",
       "      <td>9.063024e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Performance</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>9.063024e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Performance</td>\n",
       "      <td>Performance</td>\n",
       "      <td>5.771307e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Cause                 Effect         Score\n",
       "0          Log_Negativity         Log_Negativity  1.549492e+13\n",
       "1    Coherent_Information   Coherent_Information  5.482663e+31\n",
       "2   Entangling_Capability  Entangling_Capability  2.108352e+01\n",
       "3   Entangling_Capability         Expressibility  1.504357e-03\n",
       "4     Effective_Dimension    Effective_Dimension  4.910030e+01\n",
       "5     Effective_Dimension         Expressibility  3.562931e-03\n",
       "6          Expressibility  Entangling_Capability  1.504357e-03\n",
       "7          Expressibility    Effective_Dimension  3.562931e-03\n",
       "8          Expressibility         Expressibility  1.502563e-04\n",
       "9          Expressibility            Performance  9.063024e-03\n",
       "10            Performance         Expressibility  9.063024e-03\n",
       "11            Performance            Performance  5.771307e+02"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from cdt.independence.graph import DecisionTreeRegression\n",
    "# obj = DecisionTreeRegression()\n",
    "\n",
    "from cdt.independence.graph import Glasso\n",
    "obj = Glasso()\n",
    "ugraph = obj.predict(data)\n",
    "\n",
    "nx.draw_networkx(ugraph, font_size=8) # The plot function allows for quick visualization of the graph.\n",
    "plt.show()\n",
    "# List results\n",
    "pd.DataFrame(list(ugraph.edges(data='weight')), columns=['Cause', 'Effect', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3365345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PC is ran on the skeleton of the given graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Execution time : 2.69 seconds ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cause</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Performance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Performance</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Cause                 Effect  Score\n",
       "0    Effective_Dimension         Expressibility      1\n",
       "1  Entangling_Capability         Expressibility      1\n",
       "2         Expressibility    Effective_Dimension      1\n",
       "3         Expressibility  Entangling_Capability      1\n",
       "4         Expressibility            Performance      1\n",
       "5            Performance         Expressibility      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cdt.causality.graph import PC\n",
    "pc = PC()\n",
    "start_time = time.time()\n",
    "dgraph = pc.orient_directed_graph(data, ugraph)\n",
    "print(\"--- Execution time : %4.4s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# Plot the output graph\n",
    "nx.draw_networkx(dgraph, font_size=8) # The plot function allows for quick visualization of the graph.\n",
    "plt.show() \n",
    "# Print output results : \n",
    "pd.DataFrame(list(dgraph.edges(data='weight')), columns=['Cause', 'Effect', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbaeafd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1fce916",
   "metadata": {},
   "source": [
    "# FrozenLake: DDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "641f0f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log_Negativity</th>\n",
       "      <th>Coherent_Information</th>\n",
       "      <th>Entangling_Capability</th>\n",
       "      <th>Effective_Dimension</th>\n",
       "      <th>Expressibility</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.197286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>6.770000e-17</td>\n",
       "      <td>1.204012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.614762</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>6.460000e-17</td>\n",
       "      <td>1.208271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.885230</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>5.370000e-17</td>\n",
       "      <td>1.211846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.071907</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>4.550000e-17</td>\n",
       "      <td>1.211347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.829195</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Log_Negativity  Coherent_Information  Entangling_Capability  \\\n",
       "0    3.970000e-08          0.000000e+00               1.197286   \n",
       "1    3.970000e-08          6.770000e-17               1.204012   \n",
       "2    3.970000e-08          6.460000e-17               1.208271   \n",
       "3    3.970000e-08          5.370000e-17               1.211846   \n",
       "4    3.970000e-08          4.550000e-17               1.211347   \n",
       "\n",
       "   Effective_Dimension  Expressibility  Performance  \n",
       "0                  NaN             NaN         0.07  \n",
       "1                  NaN       29.614762         0.13  \n",
       "2                  NaN       22.885230         0.15  \n",
       "3                  NaN       18.071907         0.15  \n",
       "4                  NaN       16.829195         0.08  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "filename= 'PennyLane_FrozenLake-v1_Quantum_DDQN_all.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "df = df.drop([\"Unnamed: 0\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5959cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of observations to downsample to\n",
    "target_obs = df['Performance'].count()\n",
    "\n",
    "# Initialize a dictionary to hold downsampled DataFrames\n",
    "downsampled_columns = {}\n",
    "\n",
    "# List of columns to downsample\n",
    "columns_to_downsample = [\"Log_Negativity\", \"Coherent_Information\", \"Entangling_Capability\", \"Effective_Dimension\", \"Expressibility\"]\n",
    "\n",
    "# Loop through each column, downsample, and store in the dictionary\n",
    "for column in columns_to_downsample:\n",
    "    # Ensure column has enough observations for downsampling\n",
    "    if len(df[column].dropna()) >= target_obs:\n",
    "        downsampled_columns[column] = df[[column]].dropna().sample(n=target_obs, random_state=42).reset_index(drop=True)\n",
    "    else:\n",
    "        print(f\"Column {column} does not have enough observations to downsample to {target_obs}.\")\n",
    "\n",
    "# Add the Performance column to the dictionary as is, assuming it already has the correct number of observations\n",
    "downsampled_columns[\"Performance\"] = df[[\"Performance\"]].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b83fb0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log_Negativity</th>\n",
       "      <th>Coherent_Information</th>\n",
       "      <th>Entangling_Capability</th>\n",
       "      <th>Effective_Dimension</th>\n",
       "      <th>Expressibility</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.060000e-08</td>\n",
       "      <td>5.340000e-18</td>\n",
       "      <td>1.702303</td>\n",
       "      <td>3.170398</td>\n",
       "      <td>197.260690</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.320000e-07</td>\n",
       "      <td>6.490000e-17</td>\n",
       "      <td>1.608175</td>\n",
       "      <td>2.963482</td>\n",
       "      <td>162.465604</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.440000e-07</td>\n",
       "      <td>6.940000e-18</td>\n",
       "      <td>1.970827</td>\n",
       "      <td>2.956534</td>\n",
       "      <td>178.621022</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.340000e-07</td>\n",
       "      <td>-2.250000e-16</td>\n",
       "      <td>1.981273</td>\n",
       "      <td>3.127419</td>\n",
       "      <td>257.967762</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.240000e-07</td>\n",
       "      <td>1.390000e-17</td>\n",
       "      <td>1.658618</td>\n",
       "      <td>3.095283</td>\n",
       "      <td>257.889531</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>3.300000e-07</td>\n",
       "      <td>-6.090000e-17</td>\n",
       "      <td>1.985427</td>\n",
       "      <td>3.022659</td>\n",
       "      <td>92.830032</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>-3.820000e-08</td>\n",
       "      <td>1.510000e-16</td>\n",
       "      <td>1.950894</td>\n",
       "      <td>3.195781</td>\n",
       "      <td>257.889531</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>1.120000e-07</td>\n",
       "      <td>1.020000e-16</td>\n",
       "      <td>1.726487</td>\n",
       "      <td>3.273142</td>\n",
       "      <td>230.565261</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>-2.270000e-07</td>\n",
       "      <td>-3.750000e-17</td>\n",
       "      <td>1.857724</td>\n",
       "      <td>3.283833</td>\n",
       "      <td>257.889592</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>-2.860000e-07</td>\n",
       "      <td>-1.670000e-16</td>\n",
       "      <td>1.213373</td>\n",
       "      <td>3.195590</td>\n",
       "      <td>115.888285</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>531 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Log_Negativity  Coherent_Information  Entangling_Capability  \\\n",
       "0     -9.060000e-08          5.340000e-18               1.702303   \n",
       "1      2.320000e-07          6.490000e-17               1.608175   \n",
       "2     -3.440000e-07          6.940000e-18               1.970827   \n",
       "3     -3.340000e-07         -2.250000e-16               1.981273   \n",
       "4     -2.240000e-07          1.390000e-17               1.658618   \n",
       "..              ...                   ...                    ...   \n",
       "526    3.300000e-07         -6.090000e-17               1.985427   \n",
       "527   -3.820000e-08          1.510000e-16               1.950894   \n",
       "528    1.120000e-07          1.020000e-16               1.726487   \n",
       "529   -2.270000e-07         -3.750000e-17               1.857724   \n",
       "530   -2.860000e-07         -1.670000e-16               1.213373   \n",
       "\n",
       "     Effective_Dimension  Expressibility  Performance  \n",
       "0               3.170398      197.260690         0.07  \n",
       "1               2.963482      162.465604         0.13  \n",
       "2               2.956534      178.621022         0.15  \n",
       "3               3.127419      257.967762         0.15  \n",
       "4               3.095283      257.889531         0.08  \n",
       "..                   ...             ...          ...  \n",
       "526             3.022659       92.830032         0.02  \n",
       "527             3.195781      257.889531         0.00  \n",
       "528             3.273142      230.565261         0.00  \n",
       "529             3.283833      257.889592         0.00  \n",
       "530             3.195590      115.888285         0.01  \n",
       "\n",
       "[531 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all downsampled columns into one DataFrame\n",
    "# Since they are independent and have been reset index, we can simply concatenate them side by side\n",
    "data = pd.concat(downsampled_columns.values(), axis=1)\n",
    "\n",
    "# Renaming columns to ensure they retain their original names\n",
    "data.columns = downsampled_columns.keys()\n",
    "\n",
    "# Now, downsampled_df is a single DataFrame containing all the downsampled columns\n",
    "# You can inspect the first few rows to verify\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7beac766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import cdt\n",
    "# from cdt import SETTINGS\n",
    "# SETTINGS.verbose=False\n",
    "# SETTINGS.NJOBS=16\n",
    "import networkx as nx\n",
    "import time\n",
    "\n",
    "# A warning on R libraries might occur. It is for the use of the r libraries that could be imported into the framework\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d3a38f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "graphical_lasso: did not converge after 2000 iteration: dual gap: -2.614e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cause</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Log_Negativity</td>\n",
       "      <td>Log_Negativity</td>\n",
       "      <td>1.797971e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coherent_Information</td>\n",
       "      <td>Coherent_Information</td>\n",
       "      <td>6.745296e+31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>2.059516e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>4.127308e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>7.891654e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>-2.686677e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>4.127308e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>-2.686677e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>1.677722e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Performance</td>\n",
       "      <td>1.238929e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Performance</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>1.238929e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Performance</td>\n",
       "      <td>Performance</td>\n",
       "      <td>6.596546e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Cause                 Effect         Score\n",
       "0          Log_Negativity         Log_Negativity  1.797971e+13\n",
       "1    Coherent_Information   Coherent_Information  6.745296e+31\n",
       "2   Entangling_Capability  Entangling_Capability  2.059516e+01\n",
       "3   Entangling_Capability         Expressibility  4.127308e-04\n",
       "4     Effective_Dimension    Effective_Dimension  7.891654e+01\n",
       "5     Effective_Dimension         Expressibility -2.686677e-04\n",
       "6          Expressibility  Entangling_Capability  4.127308e-04\n",
       "7          Expressibility    Effective_Dimension -2.686677e-04\n",
       "8          Expressibility         Expressibility  1.677722e-04\n",
       "9          Expressibility            Performance  1.238929e-02\n",
       "10            Performance         Expressibility  1.238929e-02\n",
       "11            Performance            Performance  6.596546e+02"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from cdt.independence.graph import DecisionTreeRegression\n",
    "# obj = DecisionTreeRegression()\n",
    "# from cdt.independence.graph import HSICLasso\n",
    "# obj = HSICLasso()\n",
    "# from cdt.independence.graph import ARD\n",
    "# obj = ARD()\n",
    "\n",
    "from cdt.independence.graph import Glasso\n",
    "obj = Glasso()\n",
    "\n",
    "ugraph = obj.predict(data)\n",
    "\n",
    "nx.draw_networkx(ugraph, font_size=8) # The plot function allows for quick visualization of the graph.\n",
    "plt.show()\n",
    "# List results\n",
    "pd.DataFrame(list(ugraph.edges(data='weight')), columns=['Cause', 'Effect', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b64da06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PC is ran on the skeleton of the given graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Execution time : 2.64 seconds ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cause</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Performance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Performance</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Cause                 Effect  Score\n",
       "0    Effective_Dimension         Expressibility      1\n",
       "1  Entangling_Capability         Expressibility      1\n",
       "2         Expressibility    Effective_Dimension      1\n",
       "3         Expressibility  Entangling_Capability      1\n",
       "4         Expressibility            Performance      1\n",
       "5            Performance         Expressibility      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cdt.causality.graph import PC\n",
    "pc = PC()\n",
    "start_time = time.time()\n",
    "dgraph = pc.orient_directed_graph(data, ugraph)\n",
    "print(\"--- Execution time : %4.4s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# Plot the output graph\n",
    "nx.draw_networkx(dgraph, font_size=8) # The plot function allows for quick visualization of the graph.\n",
    "plt.show() \n",
    "# Print output results : \n",
    "pd.DataFrame(list(dgraph.edges(data='weight')), columns=['Cause', 'Effect', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ac291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5717a4cb",
   "metadata": {},
   "source": [
    "# FrozenLake: QRDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "226260eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log_Negativity</th>\n",
       "      <th>Coherent_Information</th>\n",
       "      <th>Entangling_Capability</th>\n",
       "      <th>Effective_Dimension</th>\n",
       "      <th>Expressibility</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.197286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>1.190000e-16</td>\n",
       "      <td>1.205604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.228844</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>4.800000e-17</td>\n",
       "      <td>1.209561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.272162</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>2.360000e-17</td>\n",
       "      <td>1.211865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.561727</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>2.020000e-17</td>\n",
       "      <td>1.212813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.246389</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Log_Negativity  Coherent_Information  Entangling_Capability  \\\n",
       "0    3.970000e-08          0.000000e+00               1.197286   \n",
       "1    3.970000e-08          1.190000e-16               1.205604   \n",
       "2    3.970000e-08          4.800000e-17               1.209561   \n",
       "3    3.970000e-08          2.360000e-17               1.211865   \n",
       "4    3.970000e-08          2.020000e-17               1.212813   \n",
       "\n",
       "   Effective_Dimension  Expressibility  Performance  \n",
       "0                  NaN             NaN         0.10  \n",
       "1                  NaN       32.228844         0.00  \n",
       "2                  NaN       24.272162         0.00  \n",
       "3                  NaN       20.561727         0.02  \n",
       "4                  NaN       19.246389         0.02  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "filename= 'PennyLane_FrozenLake-v1_Quantum_QRDQN_all.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "df = df.drop([\"Unnamed: 0\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5afe673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of observations to downsample to\n",
    "target_obs = df['Performance'].count()\n",
    "\n",
    "# Initialize a dictionary to hold downsampled DataFrames\n",
    "downsampled_columns = {}\n",
    "\n",
    "# List of columns to downsample\n",
    "columns_to_downsample = [\"Log_Negativity\", \"Coherent_Information\", \"Entangling_Capability\", \"Effective_Dimension\", \"Expressibility\"]\n",
    "\n",
    "# Loop through each column, downsample, and store in the dictionary\n",
    "for column in columns_to_downsample:\n",
    "    # Ensure column has enough observations for downsampling\n",
    "    if len(df[column].dropna()) >= target_obs:\n",
    "        downsampled_columns[column] = df[[column]].dropna().sample(n=target_obs, random_state=42).reset_index(drop=True)\n",
    "    else:\n",
    "        print(f\"Column {column} does not have enough observations to downsample to {target_obs}.\")\n",
    "\n",
    "# Add the Performance column to the dictionary as is, assuming it already has the correct number of observations\n",
    "downsampled_columns[\"Performance\"] = df[[\"Performance\"]].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ead1701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log_Negativity</th>\n",
       "      <th>Coherent_Information</th>\n",
       "      <th>Entangling_Capability</th>\n",
       "      <th>Effective_Dimension</th>\n",
       "      <th>Expressibility</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.000000e-08</td>\n",
       "      <td>1.210000e-17</td>\n",
       "      <td>1.204883</td>\n",
       "      <td>3.238313</td>\n",
       "      <td>112.544809</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.580000e-08</td>\n",
       "      <td>3.330000e-17</td>\n",
       "      <td>1.200077</td>\n",
       "      <td>3.217619</td>\n",
       "      <td>26.542686</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.370000e-07</td>\n",
       "      <td>-4.680000e-17</td>\n",
       "      <td>1.208229</td>\n",
       "      <td>3.223701</td>\n",
       "      <td>71.176240</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.990000e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.199487</td>\n",
       "      <td>3.235184</td>\n",
       "      <td>57.144629</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.600000e-08</td>\n",
       "      <td>-1.040000e-17</td>\n",
       "      <td>1.199020</td>\n",
       "      <td>3.231132</td>\n",
       "      <td>19.531112</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>-3.040000e-08</td>\n",
       "      <td>2.780000e-17</td>\n",
       "      <td>1.190434</td>\n",
       "      <td>3.231979</td>\n",
       "      <td>17.424525</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>-8.430000e-07</td>\n",
       "      <td>5.300000e-17</td>\n",
       "      <td>1.209481</td>\n",
       "      <td>3.230807</td>\n",
       "      <td>70.311989</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>-5.760000e-08</td>\n",
       "      <td>-1.110000e-17</td>\n",
       "      <td>1.207916</td>\n",
       "      <td>3.231397</td>\n",
       "      <td>83.795798</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>1.070000e-07</td>\n",
       "      <td>7.140000e-18</td>\n",
       "      <td>1.205904</td>\n",
       "      <td>3.222433</td>\n",
       "      <td>113.098292</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>-5.710000e-08</td>\n",
       "      <td>-1.660000e-17</td>\n",
       "      <td>1.217247</td>\n",
       "      <td>3.234436</td>\n",
       "      <td>257.889531</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>604 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Log_Negativity  Coherent_Information  Entangling_Capability  \\\n",
       "0      8.000000e-08          1.210000e-17               1.204883   \n",
       "1      4.580000e-08          3.330000e-17               1.200077   \n",
       "2      1.370000e-07         -4.680000e-17               1.208229   \n",
       "3     -2.990000e-07          0.000000e+00               1.199487   \n",
       "4     -4.600000e-08         -1.040000e-17               1.199020   \n",
       "..              ...                   ...                    ...   \n",
       "599   -3.040000e-08          2.780000e-17               1.190434   \n",
       "600   -8.430000e-07          5.300000e-17               1.209481   \n",
       "601   -5.760000e-08         -1.110000e-17               1.207916   \n",
       "602    1.070000e-07          7.140000e-18               1.205904   \n",
       "603   -5.710000e-08         -1.660000e-17               1.217247   \n",
       "\n",
       "     Effective_Dimension  Expressibility  Performance  \n",
       "0               3.238313      112.544809         0.10  \n",
       "1               3.217619       26.542686         0.00  \n",
       "2               3.223701       71.176240         0.00  \n",
       "3               3.235184       57.144629         0.02  \n",
       "4               3.231132       19.531112         0.02  \n",
       "..                   ...             ...          ...  \n",
       "599             3.231979       17.424525         0.18  \n",
       "600             3.230807       70.311989         0.12  \n",
       "601             3.231397       83.795798         0.13  \n",
       "602             3.222433      113.098292         0.09  \n",
       "603             3.234436      257.889531         0.08  \n",
       "\n",
       "[604 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all downsampled columns into one DataFrame\n",
    "# Since they are independent and have been reset index, we can simply concatenate them side by side\n",
    "data = pd.concat(downsampled_columns.values(), axis=1)\n",
    "\n",
    "# Renaming columns to ensure they retain their original names\n",
    "data.columns = downsampled_columns.keys()\n",
    "\n",
    "# Now, downsampled_df is a single DataFrame containing all the downsampled columns\n",
    "# You can inspect the first few rows to verify\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2123ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import cdt\n",
    "# from cdt import SETTINGS\n",
    "# SETTINGS.verbose=False\n",
    "# SETTINGS.NJOBS=16\n",
    "import networkx as nx\n",
    "import time\n",
    "\n",
    "# A warning on R libraries might occur. It is for the use of the r libraries that could be imported into the framework\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4c15f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "graphical_lasso: did not converge after 2000 iteration: dual gap: -6.812e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cause</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Log_Negativity</td>\n",
       "      <td>Log_Negativity</td>\n",
       "      <td>1.576511e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coherent_Information</td>\n",
       "      <td>Coherent_Information</td>\n",
       "      <td>4.804934e+32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>8.308900e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>-2.330625e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>2.687413e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>-2.330625e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>2.639795e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Performance</td>\n",
       "      <td>1.075485e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Performance</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>1.075485e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Performance</td>\n",
       "      <td>Performance</td>\n",
       "      <td>2.423614e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Cause                 Effect         Score\n",
       "0         Log_Negativity         Log_Negativity  1.576511e+13\n",
       "1   Coherent_Information   Coherent_Information  4.804934e+32\n",
       "2  Entangling_Capability  Entangling_Capability  8.308900e+03\n",
       "3  Entangling_Capability         Expressibility -2.330625e-02\n",
       "4    Effective_Dimension    Effective_Dimension  2.687413e+04\n",
       "5         Expressibility  Entangling_Capability -2.330625e-02\n",
       "6         Expressibility         Expressibility  2.639795e-04\n",
       "7         Expressibility            Performance  1.075485e-02\n",
       "8            Performance         Expressibility  1.075485e-02\n",
       "9            Performance            Performance  2.423614e+02"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cdt.independence.graph import Glasso\n",
    "obj = Glasso()\n",
    "\n",
    "ugraph = obj.predict(data)\n",
    "\n",
    "nx.draw_networkx(ugraph, font_size=8) # The plot function allows for quick visualization of the graph.\n",
    "plt.show()\n",
    "# List results\n",
    "pd.DataFrame(list(ugraph.edges(data='weight')), columns=['Cause', 'Effect', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a446018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PC is ran on the skeleton of the given graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Execution time : 3.11 seconds ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cause</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Performance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Performance</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Cause                 Effect  Score\n",
       "0  Entangling_Capability         Expressibility      1\n",
       "1         Expressibility  Entangling_Capability      1\n",
       "2         Expressibility            Performance      1\n",
       "3            Performance         Expressibility      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cdt.causality.graph import PC\n",
    "pc = PC()\n",
    "start_time = time.time()\n",
    "dgraph = pc.orient_directed_graph(data, ugraph)\n",
    "print(\"--- Execution time : %4.4s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# Plot the output graph\n",
    "nx.draw_networkx(dgraph, font_size=8) # The plot function allows for quick visualization of the graph.\n",
    "plt.show() \n",
    "# Print output results : \n",
    "pd.DataFrame(list(dgraph.edges(data='weight')), columns=['Cause', 'Effect', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b32d0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8906b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An exhaustive search of the causal structure of CGNN without skeleton is super-exponential in the number of variables.\n"
     ]
    }
   ],
   "source": [
    "from cdt.causality.graph import CGNN\n",
    "Cgnn = CGNN(nruns=16, train_epochs=2000, test_epochs=1000, batch_size=1000)\n",
    "start_time = time.time()\n",
    "ugraph = Cgnn.create_graph_from_data(data)\n",
    "print(\"--- Execution time : %4.4s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# Plot the output graph\n",
    "nx.draw_networkx(ugraph, font_size=8) # The plot function allows for quick visualization of the graph.\n",
    "plt.show() \n",
    "# Print output results : \n",
    "pd.DataFrame(list(ugraph.edges(data='weight')), columns=['Cause', 'Effect', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06247e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4c7d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8104cea1",
   "metadata": {},
   "source": [
    "# FrozenLake: Rainbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "840f1cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log_Negativity</th>\n",
       "      <th>Coherent_Information</th>\n",
       "      <th>Entangling_Capability</th>\n",
       "      <th>Effective_Dimension</th>\n",
       "      <th>Expressibility</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.197286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>1.070000e-16</td>\n",
       "      <td>1.204445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.615273</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>7.300000e-17</td>\n",
       "      <td>1.206617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.318341</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>6.660000e-17</td>\n",
       "      <td>1.207878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.177129</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>1.780000e-17</td>\n",
       "      <td>1.210306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.797902</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Log_Negativity  Coherent_Information  Entangling_Capability  \\\n",
       "0    3.970000e-08          0.000000e+00               1.197286   \n",
       "1    3.970000e-08          1.070000e-16               1.204445   \n",
       "2    3.970000e-08          7.300000e-17               1.206617   \n",
       "3    3.970000e-08          6.660000e-17               1.207878   \n",
       "4    3.970000e-08          1.780000e-17               1.210306   \n",
       "\n",
       "   Effective_Dimension  Expressibility  Performance  \n",
       "0                  NaN             NaN         0.04  \n",
       "1                  NaN       33.615273         0.13  \n",
       "2                  NaN       29.318341         0.00  \n",
       "3                  NaN       28.177129         0.00  \n",
       "4                  NaN       21.797902         0.01  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "filename= 'PennyLane_FrozenLake-v1_Quantum_Rainbow_all.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "df = df.drop([\"Unnamed: 0\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9cfc70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of observations to downsample to\n",
    "target_obs = df['Performance'].count()\n",
    "\n",
    "# Initialize a dictionary to hold downsampled DataFrames\n",
    "downsampled_columns = {}\n",
    "\n",
    "# List of columns to downsample\n",
    "columns_to_downsample = [\"Log_Negativity\", \"Coherent_Information\", \"Entangling_Capability\", \"Effective_Dimension\", \"Expressibility\"]\n",
    "\n",
    "# Loop through each column, downsample, and store in the dictionary\n",
    "for column in columns_to_downsample:\n",
    "    # Ensure column has enough observations for downsampling\n",
    "    if len(df[column].dropna()) >= target_obs:\n",
    "        downsampled_columns[column] = df[[column]].dropna().sample(n=target_obs, random_state=42).reset_index(drop=True)\n",
    "    else:\n",
    "        print(f\"Column {column} does not have enough observations to downsample to {target_obs}.\")\n",
    "\n",
    "# Add the Performance column to the dictionary as is, assuming it already has the correct number of observations\n",
    "downsampled_columns[\"Performance\"] = df[[\"Performance\"]].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f19f6fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log_Negativity</th>\n",
       "      <th>Coherent_Information</th>\n",
       "      <th>Entangling_Capability</th>\n",
       "      <th>Effective_Dimension</th>\n",
       "      <th>Expressibility</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.450000e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.173493</td>\n",
       "      <td>3.267100</td>\n",
       "      <td>62.445550</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.420000e-08</td>\n",
       "      <td>-4.160000e-17</td>\n",
       "      <td>1.198156</td>\n",
       "      <td>3.274993</td>\n",
       "      <td>80.716810</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.640000e-08</td>\n",
       "      <td>1.710000e-17</td>\n",
       "      <td>1.209754</td>\n",
       "      <td>3.262115</td>\n",
       "      <td>76.259606</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.970000e-08</td>\n",
       "      <td>3.620000e-17</td>\n",
       "      <td>1.206981</td>\n",
       "      <td>3.162023</td>\n",
       "      <td>88.504778</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.060000e-08</td>\n",
       "      <td>-2.220000e-17</td>\n",
       "      <td>1.136437</td>\n",
       "      <td>3.214411</td>\n",
       "      <td>23.207134</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>-1.720000e-07</td>\n",
       "      <td>-2.220000e-17</td>\n",
       "      <td>1.333919</td>\n",
       "      <td>3.256048</td>\n",
       "      <td>13.567764</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>-4.860000e-08</td>\n",
       "      <td>4.080000e-17</td>\n",
       "      <td>1.296516</td>\n",
       "      <td>3.273227</td>\n",
       "      <td>18.328885</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>-8.840000e-08</td>\n",
       "      <td>5.550000e-17</td>\n",
       "      <td>1.146116</td>\n",
       "      <td>3.202573</td>\n",
       "      <td>63.188102</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>-2.060000e-08</td>\n",
       "      <td>-4.130000e-17</td>\n",
       "      <td>1.220050</td>\n",
       "      <td>3.269483</td>\n",
       "      <td>110.522954</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1.410000e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.323844</td>\n",
       "      <td>3.275204</td>\n",
       "      <td>46.505761</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Log_Negativity  Coherent_Information  Entangling_Capability  \\\n",
       "0      2.450000e-07          0.000000e+00               1.173493   \n",
       "1      3.420000e-08         -4.160000e-17               1.198156   \n",
       "2     -3.640000e-08          1.710000e-17               1.209754   \n",
       "3      3.970000e-08          3.620000e-17               1.206981   \n",
       "4      5.060000e-08         -2.220000e-17               1.136437   \n",
       "..              ...                   ...                    ...   \n",
       "562   -1.720000e-07         -2.220000e-17               1.333919   \n",
       "563   -4.860000e-08          4.080000e-17               1.296516   \n",
       "564   -8.840000e-08          5.550000e-17               1.146116   \n",
       "565   -2.060000e-08         -4.130000e-17               1.220050   \n",
       "566    1.410000e-07          0.000000e+00               1.323844   \n",
       "\n",
       "     Effective_Dimension  Expressibility  Performance  \n",
       "0               3.267100       62.445550         0.04  \n",
       "1               3.274993       80.716810         0.13  \n",
       "2               3.262115       76.259606         0.00  \n",
       "3               3.162023       88.504778         0.00  \n",
       "4               3.214411       23.207134         0.01  \n",
       "..                   ...             ...          ...  \n",
       "562             3.256048       13.567764         0.14  \n",
       "563             3.273227       18.328885         0.08  \n",
       "564             3.202573       63.188102         0.12  \n",
       "565             3.269483      110.522954         0.06  \n",
       "566             3.275204       46.505761         0.09  \n",
       "\n",
       "[567 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all downsampled columns into one DataFrame\n",
    "# Since they are independent and have been reset index, we can simply concatenate them side by side\n",
    "data = pd.concat(downsampled_columns.values(), axis=1)\n",
    "\n",
    "# Renaming columns to ensure they retain their original names\n",
    "data.columns = downsampled_columns.keys()\n",
    "\n",
    "# Now, downsampled_df is a single DataFrame containing all the downsampled columns\n",
    "# You can inspect the first few rows to verify\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d753b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting 2 CUDA device(s).\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "import cdt\n",
    "# from cdt import SETTINGS\n",
    "# SETTINGS.verbose=False\n",
    "# SETTINGS.NJOBS=16\n",
    "import networkx as nx\n",
    "import time\n",
    "\n",
    "# A warning on R libraries might occur. It is for the use of the r libraries that could be imported into the framework\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e224403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "graphical_lasso: did not converge after 2000 iteration: dual gap: -1.979e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGFCAYAAABg2vAPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAA9hAAAPYQGoP6dpAABmgElEQVR4nO3dd1yV5f/H8dc5HFkKKjhRARUFB0MTcStus8isHLlXWY6ytDQbtmxopWllaY4cac5MTXMgzhBUFBeKKKA4WbLhcO7fH/4431BRwAM3yOf5ePh4yLnvc12fG8d5c1/XfV0aRVEUhBBCCFFmadUuQAghhBDqkjAghBBClHESBoQQQogyTsKAEEIIUcZJGBBCCCHKOAkDQgghRBknYUAIIYQo43T5OclgMBATE4ONjQ0ajaaoaxJCCCGECSiKQlJSEg4ODmi1ef/8n68wEBMTQ506dUxWnBBCCCGKT3R0NLVr187zeL7CgI2NjbExW1tb01QmhBBCiCJ1584d6tSpY/wcz0u+wkDO0ICtra2EASGEEKKUedQQv0wgFEIIIco4CQNCCCFEGSdhQAghhCjjJAwIIYQQZZyEASGEEKKMkzAghBBClHESBoQQQogyTsKAEEIIUcZJGBBCCCHKOAkDQgghRBknYUAIIYQo4yQMCFFIhw4d4t9//1W7DCGEeGwSBoQopJEjR9K6dWu6dOnCoUOH1C5HCCEKTcKAEIWk1+sBCAgIoG3bthIKhBClVr62MBZC5C07OxsAf39/2rZti6OjI1999RVr167F0tKSWrVq4eHhgaenJ25ubpQrV07lioUQIje5MyBEASmKws6dO7l27dp9rwMYDAb0ej0pKSlcvXqVP/74gyFDhuDh4UHFihUZNmwYBw8eNJ4vhBBqkzAgRAEcOnQId3d3unfvbhwmMDMzA6Bjx44EBAQQHR3N4MGD2b59O3v37uXy5cskJCSwb98+pk+fzoEDB2jXrh0eHh7s3btXxasRQoi7JAwIkQ/Z2dl88skndOjQAVtbWwICAqhbty4A7dq1IyAggL1799KhQ4cHvr9ixYq0b9+e6dOnc+HCBXbu3EnlypXx9fVl3LhxJCcnF+flCCFELholH/cq79y5Q8WKFUlMTMTW1rY46hKixDAYDAwZMoTVq1fzwQcf8P7776PT6di/fz8ajYZ27doVut0ffviBqVOn0rBhQ3bv3o2dnZ2JqxdClGX5/fyWMCDEI0yePJlvv/2WNWvW8NJLL5m8/dDQUHx9fXF2dmbXrl1UqlTJ5H0IIcqm/H5+yzCBEA+xatUqvvnmG77//vsiCQIA7u7u7N69m0uXLtG/f3+ZWCiEKHYSBoTIQ3JyMlOmTOGFF15g/PjxRdqXp6cnK1eu5J9//uG3334r0r6EEOJeEgaEyMNXX31FXFwc33zzTbH017NnTwYNGsSkSZOIi4srlj6FEAIkDAjxQNnZ2SxatIgxY8bg5ORUbP1+8803JCcny90BIUSxkjAgxAMEBARw/fp1Bg0aVKz9Vq9enT59+rBw4UKZOyCEKDYSBoR4gM2bN+Pk5ETLli2Lve+RI0dy5swZQkNDi71vIUTZJGFAiAc4ffo0zZs3R6PRFHvfbdu2RaPRcOzYsWLvWwhRNkkYEOIBwsLCcHV1VaVvGxsbXFxcCAkJUaV/IUTZI2FAiAe4ceMGtWrVUq1/FxcXIiMjVetfCFG2SBgQ4gHMzc3JyspSrX+tVv5pCiGKj/yPI8QDmJubk5GRoVr/8iSBEKI46dQuQIiSqE6dOoSHhxfqvSkZei7HppCpN2Cu0+JsX57yFgX7pxYdHU2bNm0K1b8QQhSUhAEhHsDb25sjR47k+/wLN5JYGRiFf9hNouJS+e/P9RrA0c4aX9dqDPJxpEF1m4e2lZ6eztmzZ3n99dcLV7wQQhSQhAEhHqBly5YsXryY2NhY7O3t8zwvOi6V9zaGsj/8NmZaDdmG+2/vK0BkXCrLAyNZevgy7V2qMPN5d+rYWT+wzWPHjqHX6/Hy8jLR1QghxMPJnAEhHuC5557DzMyMZcuW5XnO6qAoun4XwKGIWIAHBoH/yjl+KCKWrt8FsDoo6oHnLVu2jNq1a+Pt7V3I6oUQomAkDAjxANWqVePFF19kwYIFGAyG+47P97/A1A2hZOgNjwwB98o2KGToDUzdEMp8/wu5jiUnJ/P7778zcuRIzMzMHusahBAivyQMCJGHiRMncuHCBRYsWJDr9dVBUcz+57xJ+pj9z3nW/OcOwaeffkpmZiajRo0ySftCCJEfEgaEyEOrVq149dVXeffdd40LAEXHpfLR5tMm7efDzaeJjkvl2LFjfPPNN3z00Uc4OjqatA8hhHgYjZKPB5rv3LlDxYoVSUxMxNbWtjjqEqJEuHPnDk2aNKF69ers2rWLCevDOBQRW+ChgYcx02p4qlYFjn83Cmtra4KDgylXrpzJ2hdClF35/fyWOwNCPIStrS1//fUXly5dosvzg9gfftukQQDuziE4Ep1EunklNm7cKEFACFHsJAyIJ46zszOurq54eXnRuHFjfvjhhwK38fPPP+Pm5oaXlxd16tRh586dxJSvD4bsIqgYFEM2L0ydQ7169YqkfSGEeBhZZ0A8kdasWYOXlxeRkZF4eHjQvn17PDw8Hvk+vV6PTqdjzpw5LFmyhNatWwNgb2+Pc5tbXEvSP/T9iiEbjbbgTwFotGYcv5FZ4PcJIYQpSBgQTzQnJydcXV05ceIE8+bN48SJE6Snp9OqVSvmz5+Pubk5nTp1wsPDg6CgIKysrLCzs+PixYsMHz4cd3d31q1bx8LFSzk652MAdLZVsOs5Hp1NFZJP7iL51G7MLG3Iir+Kfc/xXF8+hUodhpB6IZDslATsuo4hKzaa1LBDGDJSsO85AUsnDxRDNjfXzsCQloSiz+R2tbrcHNmcanYV2bt3L+PHj6dDhw4cPHgQvV7PsmXLaNGiBQBbt25lxowZZGZmotFo+Pnnn/Hx8SEoKIh3332XO3fukJ2dzXvvvcdLL72k5h+BEKIUkGEC8UQLDQ3l3LlzLF68mPbt23PkyBFOnDiBwWBg7ty5xvPOnz/Pvn372LNnD+vWrcPBwYE1a9awbt06Tp06xbSp71Kt3wwcRs3HolYjYv+eZ3xvZsx5KnUcisOoH7Co1QgATTlLag77FvunJ3L7r28wK29HzeFzqNRxGPH+S+6+UaOlit8Uag6fQ81RP6CxsOaL2d8Z2z137hzDhg3jxIkTTJgwgenTpxtrHTFiBMuXL+fEiRMEBQXh5uZGQkICr7zyCitXriQ4OJidO3fy9ttvc/Xq1WL4TgshSjO5MyCeSP3798fKygpra2sWL17M66+/zqxZs/j2228BSEtLy7Woz+DBg/OcuOfv70+bjl04aVMFgArNe5Nw8HeU/58/YFHLjXL2tXO9p3yjDneP1WiAkpVO+cb//3XNhmTFx/z/WQp3gv4kLTwIlGwMGamcOWVpbMPFxQUfHx8AWrduzezZswHYuXMnPXv2xM3NDYBy5cpRsWJFtm3bRkREBL169cpVS1hYGLVq1SrYN1AIUaZIGBBPpJw5Azlee+011q9fT8OGDR94foUKFR7anlbzv99r7jmmMbe673yN7v+DhVb7/1+b//8BrXESYsrpADIiT1Bj0JdoLay5E7wZfeYVYxuWlv8LBmZmZuj1j5ivoCg0adKEQ4cOPfQ8IYS4lwwTiDKhT58+fPXVV8YP1Pj4+HxvUezr68vhfXvITrq7B0HS8b+xdPIs1ETB/zKkJ6O1skVrYY0hI5WU0N1Ymz86n/fo0YMdO3Zw7tw5ALKyskhMTKRNmzZcunSJXbt2Gc8NCQkhM1MmJgohHk7CgCgTvvvuO6ysrPDy8sLDw4MuXbpw+fLlfL23adOmzJ41i/j1HxPz63gyrpzGvteEx66pQtPOKFkZXP3lVW6unUGVBp6Yae+973A/FxcXlixZwuDBg/H09MTHx4ewsDAqV67M1q1bmTlzJp6enjRu3JipU6c+cG8FIYT4L1mBUIh8mrH5NMsDI02+6BDcXYVwiI8TM/yamLxtIUTZJSsQCmFig3wciyQIwN1VCAe3kv0IhBDqkDAgRD41qG5De5cq+bqVXxBmWg3tXargUs3GpO0KIUR+SRgQogBmPu+OzsRhQKfVMPN5d5O2KYQQBSFhQIgCqGNnzccmHtf/xK8JdeysTdqmEEIUhIQBIQpogLcjk7s/eL2CgprS3ZX+3jJXQAihLll0SIhCGO/bgCoVLPho82n0BqVAEwvNtBp0Wg2f+DWRICCEKBHkzoAQhTTA25FdkzrSpp49wCMnFmq4Gxja1LNn16SOEgSEECWG3BkQ4jHUsbNm+SgfLtxIYmVgFP7nbxIVm8p/7xNoALO0OJIvHMF/4Sc0cqisVrlCCPFAsuiQECaWkqHncmwKmXoD5jotzvbl8W3fhqCgIDp06MDu3bvR6SSHCyGKniw6JIRKylvoaOJQkWaOlWniUJHyFjqqVq0KwL59+xgwYMAjNx0SQkDLli3x9PRk8+bN5OPnVvEYJAwIUQwuXbpk/P2GDRsYOHCgBAIhHiEyMpKTJ0/y3HPPSSgoYhIGhChiiqLkCgOKorB+/XoJBEIUwOnTp3nuueeoX78+P//8MzExMezYsYO9e/dy8eJF2ZDrMcmcASGK2NWrV6ldu3au17RaLQaDgZCQEDw9PVWqTIiSS6/XU6VKFRITE+87ptVqGThwICtXrjS+VqFCBTw8PHjqqacYMmQILVq0QKMx7WqhpZHMGRCihLhw4QJw9z8wAI1Gw6RJkwgMDJQgIMQ90tPT+eqrr6hXr16uIKDVatFqtfTr148TJ06wZMkSoqKiCAsLY/v27XzwwQc4OzuzceNGWrZsSbNmzfj555/l7ls+yZ0BIYrYmTNnGDJkCJ07d+by5cusW7eOAwcO0LZtW7VLE6JEOXXqFAMHDuT8+fMMGjSITZs2ER8fj5mZGcOHD2f69OnUrVv3oW1kZ2ezY8cOFi5cyObNm2nWrBlLlizB3b1s7v+R389vCQNCFKOYmBhq1arFM888w19//aV2OUKUGGvWrGH48OHUr1+f33//HXd3d0aPHg2QrxDwIEFBQQwfPpwLFy4wZ84cXn/9dVOXXeJJGBCihHJwcODOnTskJyerXYoQJcKOHTt45pln6NevH4sWLcLKyspkbWdkZDBlyhTmzZvH/PnzGTdunMnaLg1kzoAQJdTzzz9PSkoKhw8fVrsUIVQXGhrKCy+8QI8ePVi2bJlJgwCAhYUFc+fOZdKkSYwfP55ly5aZtP0nhdwZEKKY5QwV+Pn58eeff6pdjhCqURSF9u3bEx8fz5EjRyhfvnyR9jVixAjWr1/PmTNnqFOnTpH1VZLInQEhSigHBwdq1KjBnj171C5FCFX9/vvvHDx4kO+//75IgwDcfYpn7ty52Nra8tprr8niRfeQMCCECvr06UNycjKBgYFqlyKEKhRFYebMmTz77LN06dKlWPqsWLEi8+bNY+vWrRw6dKhY+iwtJAwIoYJp06YB8MUXX6hciRDqCA0N5fTp07zyyivF2m+fPn2oW7cuixYtKtZ+SzoJA0KowNHRkerVq8tQgSiz1qxZg52dHd27dy/WfrVaLaNGjWLNmjUkJSUVa98lmYQBIVTSp08fkpKSCAoKUrsUIYrdkSNH6NixI+bm5sXe93PPPUdaWhrHjh0r9r5LKgkDQqjkvffeA2SoQJRNYWFhuLq6qtK3m5sbFhYWhISEqNJ/SSRhQAiVODo6Uq1aNXbt2qV2KUIUq6ysLKKjo3FxcVGlf51OR6NGjTh9+rQq/ZdEEgaEUNFzzz1HUlISwcHBapciRLHJ2U3QzMxMtRoqVKhARkaGav2XNBIGhFDR9OnTARkqEGWLTqdDq9XKh3EJImFACBU5OTnJUIEok2xtbbl9+7Zq/SclJWFpaala/yWNhAEhVObn58edO3dkZrMoU5o1a8bRo0cL9d6UDD2nYxI5HhXP6ZhEUjL0BXp/ZmYmZ8+epWnTpoXq/0mkU7sAIcq6999/n0WLFjFz5kzWrVundjlCFAtvb29WrlyJoijGOQQPc+FGEisDo/APu0lUXCr/XUxYAzjaWePrWo1BPo40qG7z0LbOnTtHZmYmXl5ej3UNTxK5MyCEypycnKhatSo7d+5UuxQhik3Xrl25evXqI3fvjI5LZcivgXSbs4/lgZFE3hMEABQgMi6V5YGRdJuzjyG/BhIdl5pnmxs2bKBChQo0b9788S/kCSFhQIgSIGeoQJ57FmVFly5dqF+/PgsWLMjznNVBUXT9LoBDEbEAZBsevrlQzvFDEbF0/S6A1UFR95+Tnc3ixYsZOHBgkW+OVJpIGBCiBMh5quDzzz9XuRIhiodWq+XVV19lzZo1hIeH33d8vv8Fpm4IJUNveGQIuFe2QSFDb2DqhlDm+1/IdeyPP/4gOjqa0aNHP1b9TxqNko99HPO7H7IQovCqVq1KVlYWCQkJapciRLFISUnB3d0dR0dH9uzZg1Z79+fT1UFRTN0QarJ+vurrTn9vR2JjY2ncuDEdOnRg7dq1Jmu/JMvv57fcGRCihHj22WdJTEyUoQJRZpQvX56FCxcSEBDAd999B9ydI/DRZtOuDPjh5tNE3k5m3LhxZGZmMm/ePJO2/ySQMCBECZEzVDBz5kyVKxGi+HTp0oV33nmHyZMn88svv/DexlD0BRwWeBS9QaHvF2v5448/+Pnnn6lRo4ZJ238SyDCBECVIlSpV0Ov1MlQgyhRFUXjjjTdYsGoTDmN+KrJ+XneK5Z2xQ4us/ZJIhgmEKIWeeeYZEhMTCQ013XipKFv0ej0ff/wxbm5uNG3aFC8vL1555ZWHBswZM2bw5ptvFluN90pMTKRmzZp0HP0+iiH7oedGfvkMhvTkR7aZFX+Na0veIGbxRJJP7kSLQqrDU6YqOV/mzJnD9evXjV8vWLCAWbNmFWsN+SVhQIgSRIYKxOMaNWoUwcHBHD58mFOnTnH8+HG6detGXFxckfZrMBgwGAyFem9CQgJfffUVmfYN0GhNs3lRathBzGs2wGHk91Tw6IYBDf7nbz7yfXp9wVYzfJh7w8DYsWOZMmWKydo3JVmBUIgSpEGDBtjb27N9+3a1SxGlUHh4OGvXriUqKorKlSsDd3cIfOmllwCYNWsWS5cuRavV4uHhwY8//kjFihUBuHbtGs8++ywXL16kRo0arFu3Djs7OwBmz57NH3/8gV6vp1q1avz88884OTkxY8YMQkNDSU5OJjo6mp07d3Lq1Ck+/fRT0tLSMDMz46uvvsLX15e9e/cyfvx4OnTowMGDB9Hr9SxbtowWLVowduxYkpKSODx7FBqtGTWHz8nX9V75cSQVmnYm7fJxslMSqODRjUptB5Acups7QZvAYCAjJowqflPQmOk48vsPNF2Wjc7MjBkzZtCnTx/j9+jDDz9k27ZtdOrUiVu3bmFubk5ERAQXL17E19eXsWPH8s477xAVFUWfPn349ttvAfj222/5/fffycrKoly5cnz//fe0bt2aTz75hJiYGPr374+VlRVLly5l06ZNJCQkMGfOHLKzs5k6dSp///03AL6+vnzzzTeYm5szfPhwLCwsCA8PJzo6mqZNm7J69WrMzc1N9DflfnJnQIgSpnfv3iQkJMhe66LAjh07RoMGDahSpcp9x/7++28WL17MwYMHCQ0NpXz58kydOtV4PDAwkKVLl3LmzBnjBz7AqlWrCAsL4/Dhwxw7doxBgwbx+uuvG993+PBhfvvtN86cOUNGRgYzZsxg27ZtHD16lFWrVvHyyy8bdyc8d+4cw4YN48SJE0yYMMF4J2zBggWUr1ABh5Hz8h0EchgyUqg59BtqDvuWO0c2oE+6TQX3Lth49aJ8k044jJyHeRVHbm+ejbVbO9bsOMDatWsZNWoUkZGRxnbMzMwICgoy3sYPDQ1ly5YthIWFsW/fPr744gt27txJaGgoK1euNP77HDJkCEFBQYSEhDBv3jxGjBgBwIcffoiDgwNr1qwhJCTkvqWPf/nlF4KCgjh69CghISFcvHjR+EQFQEhICH/99Rdnz57lxo0brF+/vkDfl4KSMCBECfPee+8BsgCRMK1du3bRv39/KlWqBMBrr72Wawnsnj17Ym9vD0Dr1q25ePEiAJs2bWLXrl089dRTeHl58fXXXxMV9b+V/Z5++mmqV68OwPbt2wkPD6dDhw54eXnx4osvotVqjee7uLjg4+NzXx/AfUsM51f5xh0BMLOuiK5iDfQJN+47x5CRSuaNi1Tw7E6m3kCDBg1o164d+/fvN54zcuTIXO957rnnsLS0xNzcHHd3d3r06EG5cuUoX748jRs35sKFu4sZHT9+nI4dO9K0aVPGjh1LWFgYaWlpj6x7165dxjsAOp2OMWPG5PrzeP7557G2tsbMzIyWLVvm+l4VBRkmEKKEcXV1xc7OToYKRIE1b96cCxcuEBsba/xgz8u9mwP9dztfMzMz49i5oihMmzaNV1555YHtVKhQwfh7RVHo1q0bq1atuu+8q1ev5tkH3N1sqDA0uv/dOtdotfCICYjmurs/A997/f+9Drj/+/Gg2jMzM+nbty/+/v54e3sbZ+5nZGRgZWVVsOvI559HUZE7A0KUQL179yY+Pl6GCkSBuLi48MILLzBq1Cjj0wOKorB+/Xrq1avHH3/8wZ07dwD4+eef6d69+yPb7NOnDwsWLDBOQMzKyuL48eMPPLdHjx7s2rWLkydPGl87cuTII/uwtbUlIz0dsrMeeW5haC2sMa9en5STO3G2L094eDgHDhygQ4cOj9Vueno6mZmZODo6Aty3mJGtrS2JiYkPfG/Xrl357bffyMzMRK/Xs2jRonz9eRQVuTMgRAk0ffp0li9fzsyZM1m5cqXa5YhSZPHixXz22Wf4+Pig0+kwGAx06NCBr776itTUVFq3bp1rAuGjDBo0iNjYWHx9fYG7s+1HjhxJs2bN7jvXxcWFVatW8eqrr5KamkpmZibNmjV74J2C/7Kzs2Po0KGsXDqRbDOLAs8byI8qfpNJ3b2ANi2fQqPRsGjRIuOHeGHZ2try2Wef0bJlS6pUqcKAAQNyHZ84cSJjxozB2tqapUuX5jr2yiuvcPHiRePOiZ06dVL18U5ZdEiIEsre3h5FUYr8kTAhSooZm0+zPDCywBsT5YeZVsMQHydm+DUxedslmSw6JEQp16tXL+Lj4zl79qzapQhRLAb5OBZJEIC7OxkObvV4dwKeZDJMIEQJ9d5777Fy5Uo+//xzVqxYoXY5QhS5BtVtaO9ShQ1fTSQr8VauY1rLCtR4+YtCtWum1dCmnj0u1WxMUeYTSYYJhCjB7Ozs0Gg0xMbGql2KEMUiOi6Vrt8FkKEv3GqGD2Kh07JrUkfq2FmbrM3SQoYJhHgC9OrVi7i4OMLCwtQuRYhiUcfOmo9NPK7/iV+TMhkECkLCgBAlmCxAJMqiAd6OTO7e0CRtTenuSn9vmSvwKDJMIEQJV7lyZczMzLh9+7bapQhRrFYHRfHR5tPoDUqBJhaaaTXotBo+8WtS5oOADBMI8YTo2bMnsbGxnD9/Xu1ShChWA7wd2TWpI23q3V1N0Uz78HUKc463qWfPrkkdy3wQKAi5MyBECXfq1Cnc3d0ZOnQoy5YtU7scIVRx4UYSKwOj8D9/k6jY1Fx7GWgAR3trfBtWY3ArR3lq4D/y+/ktYUCIUkCGCoT4n5QMPZdjU8jUGzDXaXG2L095C3lS/kFkmECIJ0iPHj2IjY0t8p3LhCgNylvoaOJQkWaOlWniUFGCgAlIGBCiFMh5quCzzz5TuRIhxJNIwoAQpYCHhwcVK1Zky5YtapcihHgCSRgQopTo3r07t2/flqECIYTJSRgQopR4//33AVmASAhhehIGhCglZKhACFFUJAwIUYp069aNW7ducenSJbVLEUI8QSQMCFGKyF4FQoiiIGFAiFKkWbNm2NrasnnzZrVLEUI8QSQMCFHK5AwVREZGql2KEOIJIWFAiFJm6tSpgCxAJIQwHQkDQpQyLVq0wMbGRoYKhBAmI2FAiFKoa9eu3Lx5U4YKhBAmUWrDwPvvv8/EiRO5evWq2qUIUeymTZsGwMyZM1WuRAjxJCi1WxjXr1+fiIgIdDodr776KtOmTaNWrVpqlyVEsbG1tcXa2prr16+rXYoQooQqM1sY6/V6FixYgLOzM+PGjSMyMhJFUcjMzCQfOUeIUqtLly7cuHGDqKgotUsRQpRypTYMZGdn5/q9Xq/nxx9/pG7dukycOBELCwvMzMyoXbs2vXv3Ztq0aaxbt47U1FQVqxbCdHIWIPriiy9UrkQIUdqVumGCkJAQvv/+e5YsWXLfsUqVKjF27FjGjh1LQEAAaWlpXL58mZMnT3LixAmuXr1KxYoVGTx4MK+88goeHh4qXIEQpmNjY0OFChW4du2a2qUIIUqg/H5+l5owkJ6ezrRp05gzZw516tQhJSWFuLg4AGrVqsWMGTMYOnQo5ubmebYRERHBr7/+yuLFi7l+/Tpjx47l66+/xsbGprguQwiT6tOnD3/++SfR0dHUrl1b7XKEECXMEzVn4OLFi7Rq1Yoff/yR7777joiICNzc3KhVqxYLFy4kIiKC0aNHPzQIANSrV4/PP/+cqKgo5s+fz/Lly2natCn79u0rpisRwrTkqQIhhCmU+DsD165do02bNuh0OtatW4enpycAmZmZaLVadDpdodu+dOkSw4cP58iRI2zdupXOnTubqmwhio0MFQgh8vJE3Bm4c+cOvXr1Iisriz179hiDAIC5ufljBQGAunXrsmPHDjp06MCzzz7L/v37H7dkIYqdr68v169f58qVK2qXIoQopUp0GPjggw8IDw9n+/bt1KlTp0j6sLS0ZNOmTbRo0YIBAwaQmJhYJP0IUVRy9iqQpwqEEIVVYsPA6dOn+eGHH/jggw9o2rRpkfZlZWXF8uXLuXPnjvE/ViFKizZt2lC+fHk2btyodilCiFKqxIaBDz/8EGdnZ958881i6c/R0ZEvvviCBQsWcPLkyWLpUwhT8fX15dq1a8TExKhdihCiFCqRYSAhIYEtW7Ywfvx4LCwsiq3fV199lerVq7Nw4cJi61MIU3j33XcBGSoQQhROiQwDGzZsICsri379+hVrv+XKlWPEiBGsWLGCtLS0Yu1biMfRrl07ypcvz4YNG9QuRQhRCpXIMODv74+3tzcODg7F3vfLL79MQkIC//77b7H3LcTj6NixIzExMbJxkRCiwEpkGAgLC6Nx48aq9N2oUSMsLS05ceKEKv0LUVgyVCCEKKwSGQbOnz+Pq6urKn3rdDrc3d0JCQlRpX8hCqtDhw5YW1uzbt06tUsRQpQyJTIMpKWlUaFCBdX6r1q1qqw3IEqlnKGCGzduqF2KEKIUKZFhwMLCgoyMDLXLEKLUyVkn48svv1S5EiFEaVIiw4C1tTXJycmq9Z+z74EQpU3OUMHatWvVLkUIUYqUyE+8xo0bF3oCX0qGntMxiRyPiud0TCIpGfoCt3H27FnV5iwI8bg6dOjA1atXuXnzptqlCCFKicfb6aeIeHt7s2rVqnyff+FGEisDo/APu0lUXCr/3YZRAzjaWePrWo1BPo40qG7z0LZu377N1atXc22KJERp8u6777J9+3a+/PJLvv32W7XLEUKUAiXyzkC7du24cuXKI5cFjo5LZcivgXSbs4/lgZFE3hMEABQgMi6V5YGRdJuzjyG/BhIdl5pnm7t27QKgZcuWj3kVQqijU6dOWFlZyVCBECLfSmQY6NmzJzVr1uTnn3/O85zVQVF0/S6AQxGxAGQb7o0BueUcPxQRS9fvAlgdFPXA8xYuXEj79u2pW7duIasXQn0dOnTgypUr3L59W+1ShBClQIkMA+XKlWP06NEsX778gf+Zzfe/wNQNoWToDY8MAffKNihk6A1M3RDKfP8LuY6dOXOGPXv2MGbMmMeqXwi1TZkyBZAFiIQQ+aNRFOWRn6Z37tyhYsWKJCYmYmtrWxx1cePGDRo1asTTTz/NihUrjK+vDopi6oZQk/XzVV93+ns7YjAY6NSpE9euXSM0NBRLS0uT9SGEGqytralSpQpRUQ++CyaEePLl9/O7RN4ZAKhevTpz5sxh5cqVbN68Gbg7R+CjzadN2s+Hm08THZfKggUL2L9/P7/88osEAfFEaNeuHdHR0TJUIIR4pBIbBgCGDBmCn58fAwcOZN++fby3MRR9AYcFHkVvUBj9827eeOMNXnvtNXx9fU3avhBqyRkq+Oqrr1SuRAhR0pXYYYIcqampPPvsswSfv0LlwUX3mJRH9J9sWPojOl2JfNpSiEKxsrKiWrVqREZGql2KEEIFRT5M4OzsXKSb+SxduhSNRsP69ev566+/cO42hNTz/3J95VTTd6YY8HxxAleuXGHBggW5Dj399NOEhYU99O0xMTG0b9/e+PWMGTNIT083fZ1CFFC7du2IiooiLi5O7VKEECVYiR4mcHJy4sMPP0Sn01GxURsoqiWCNVr2hd/m8uXL94WBbdu2PXI1QgcHB/bv32/8+uOPP5YwIEqEyZMnAzJUIIR4OJN+uu7YsYPmzZvj4eFBx44dOXPmjPHYRx99hIuLC97e3rz//vs4Ozs/sj0vLy+aN2/Ot3O/Jzou7b7jaRFHub7iHa4teYNryyaRHvm/RYoS9q/k6oIxXFs6ifh9y7ny40gAFEM2N9Z8wLWlbxKz6HVubZ6FITOdqNhUXnl1LGFhYXh5eeHn5wf87w7IwYMHcXd3z9V/p06d+PPPP7l8+TKVKlUCYOzYsQC0b98eLy8voqKiqF69Oqmp/1vo6OWXX+ann37K3zdViMfQo0cPLC0tWb16tdqlCCFKMJOFgZs3b/Lyyy+zbNkyTp48ySuvvMKLL76Ioihs3bqV9evXc/z4cY4cOcLVq1fz3e7MmTOZPWsW2Rm5Vw3MSrhOwoFVVHtpBjVHzKWK3xRub56Fos8iNTyI1LCD1BwxlxrDviU7KfZ/b9RoqeI3hZrD51Bz1A9oLaxJOvoXCjDt89m4uroSEhJifIIhR9u2bcnIyCA4OBiAiIgIwsLC6N27d67zcu4s7N+/n5CQEBwdHenatavx8cgbN26wa9cuhgwZku/vgRCPo23btjJUIIR4KJOFgcDAQNzd3Y0/PQ8aNIiYmBiuXr3K7t27eemll7CxsUGj0TBq1Kh8t+vq6kqHrj1J/HddrtfTI46ij7/G9ZXvErN4Arc2fgEaDfo7N0mPDMHarR1aC2s0Gg0VPLr9550Kd4L+JGbxRK4tHk/axWAyb0YAoM9++FzKESNGsGTJEgCWLVvGoEGD8jXh8I033uCHH34A7q5wOHDgQCpUqJDv74EQj+Ptt98G4Ouvv1a5EiFESaXK1HmNRlOg8ydMnsaf7XzQVaz2vxcVBcu6zajqNyU/HRp/m3I6gIzIE9QY9CVaC2vuBG82Di/ozB5e17Bhw/D09GT27Nn89ttvbNmyJV/1t2zZEmtra/z9/fnll1+M+x8IURx69eplHCr48ssv1S5HCFECmezOQKtWrQgNDeXUqVMArF69mlq1alGrVi06d+7M+vXrSU5ORlEUFi9eXKC2WzZxwcazO4mH/7fximW95qRfDiHz5iXjaxkxd2f9Wzp5khp2CENmGoqikHxyp/EcQ3oyWitbtBbWGDJSSQndDdzd3bBh7WokJibmWYeDgwPe3t5MmjSJatWq0aRJkweeZ2Njc187b7zxBkOHDqVRo0Y0bNiwQNcvxONq06YNkZGRJCQkqF2KEKIEeqw7Az169KBcuXLGr+fOncvQoUPR6/VUrlyZtWvXotFoeOaZZwgMDMTLy4tKlSrRsWNH44S7/ChvoaNJr6H8G7LD+Fq5yg5U8ZtC7Pb5KFkZKAY95tXrU9VvCtYuLcmMCePa4oloLctjUacpWsvyAFRo2pm0C/9y9ZdXMbOuiEXtxujv3MLR3hqfFs1p0qQJTZs2pV69evfNG4C7QwX9+vV76ATAt99+m27dumFtbc0///xDtWrVePHFF3nttdcYP358vq9bCFN5++232bNnD19//TUzZ85UuxwhRAlTbIsOJSUlYWNjg6IovP3226SlpRVoRv2MzadZHhiZ742JDBmpaC2sURSF+D2LUPSZ2PcY98BzzbQahvg4McPvwT/pm0JwcDAvv/wy586dQ1tUj0gK8RCWlpbUrFmTS5cuPfpkIcQTIb+f38U2Z2Do0KFcvnyZ9PR0mjRpct/z/I8yyMeRpYcv5/v821u+RZ94EyU7E/MqjtjlEQTg7k6Gg1s5Fqieghg9ejT//PMPixYtkiAgVNO6dWv27t1LQkJCge7MCSGefKouRxwSEsLw4cPve33YsGFMmjTpvteH/BrIoYjYAm9b/DBmWg1t6tmzfJSPydoUoiT666+/8PPz47333uPzzz9XuxwhRDHI7+d3id+b4L+i41Lp+l0AGXqDydq00GnZNakjdeysTdamECWVpaUlDg4OREREqF2KEKIYlPotjB+kjp01H5t4XP8TvyYSBESZ0apVKy5dusSdO3fULkUIUYKUqjAAMMDbkcndTfNo3pTurvT3Lrq5AkKUNDnDb7NmzVK5EiFESVKqhgn+a3VQFB9tPo3eoBRoDoGZVoNOq+ETvyYSBESZZGFhQe3atbl48aLapQghitgTOUzwXwO8Hdk1qSNt6tkDdz/kHybneJt69uya1FGCgCizWrVqRUREhAwVCCGMSm0YgLtzCJaP8mHnmx0Y4uOEk70190YCDeBkb80QHyd2TerA8lE+MkdAlGlvvvkmAN988426hQghSoxSO0yQl5QMPZdjU8jUGzDXaXG2L095C1W2YBCiRDIYDFhZWVGnTh3Cw8PVLkcIUYRK3KJDxaW8hY4mDhXVLkOIEkur1eLj48P+/fuNK4MKIcq2Uj1MIIQonDfeeAOQoQIhxF0SBoQog55//nnMzc1ZsWKF2qUIIUoACQNClEFarZaWLVsSERFBcnKy2uUIIVQmYUCIMmrixIkoisK3336rdilCCJVJGBCijHrhhRcoV66cDBUIISQMCFFWabVavL29CQ8PJzU1Ve1yhBAqkjAgRBkmQwVCCJAwIESZ9tJLL1GuXDl+++03tUsRQqhIwoAQZZhWq6VFixYyVCBEGSdhQIgybsKECSiKwpw5c9QuRQihEgkDQpRx/fv3R6fTsWzZMrVLEUKoRMKAEGVczlDBhQsXZKhAiDJKwoAQgvHjx6MoCnPnzlW7FCGECiQMCCEYOHCgDBUIUYZJGBBCoNVqeeqppzh//jxpaWlqlyOEKGYSBoQQwP+GCr7//nu1SxFCFDMJA0IIAF5++WV0Oh1Lly5VuxQhRDGTMCCEAO4OFTRv3pywsDDS09PVLkcIUYwkDAghjF5//XUURWHevHlqlyKEKEYSBoQQRkOGDEGn07FkyRK1SxFCFCMJA0III61WS7NmzTh37pwMFQhRhkgYEELkkjNU8MMPP6hdihCimEgYEELkMnToUMzMzFi8eLHapQghiomEASFELlqtFi8vL86ePUtmZqba5QghioGEASHEfV577TUZKhCiDJEwIIS4z4gRIzAzM+PXX39VuxQhRDGQMCCEuI8MFQhRtkgYEEI80NixYzEYDPz4449qlyKEKGISBoQQDzRy5EgZKhCijJAwIIR4IK1Wi6enJ2fOnJGhAiGecBIGhBB5evXVVzEYDCxYsEDtUoQQRUjCgBAiTzlDBYsWLVK7FCFEEZIwIITIk06nw93dndOnT5OVlaV2OUKIIiJhQAjxUDJUIMSTT8KAEOKhRo8ejVarlaECIZ5gEgaEEA+l0+nw8PDg1KlT6PV6tcsRosgNGDAAFxcXVqxYUWb+zksYEEI80pgxYzAYDPzyyy9qlyJEkbt06RIXL15kyJAhuLq6lolQIGFACPFIr7zyClqtVsKAKHMuXbrEkCFDcHR0ZObMmSQkJLBz504CAgI4f/482dnZapdoEjq1CxBClHw6nY6mTZsSGhqKXq9Hp5P/OsSTSVEUEhMTc30NcO3aNaZPn05kZGSuUGxtbU3Tpk1p1qwZAwYMoGPHjmg0mmKv+3HJnQEhRL7kDBUsXLhQ7VKEMLns7GwWLlxI06ZNCQsLM76u1d79mOzWrRv79u3jp59+4vLly4SFhbFz504+/fRT3Nzc2LVrF76+vri5uTF79mzS0tLUupRC0Sg5sech7ty5Q8WKFUlMTMTW1rY46hJClDB6vR4LCws8PDw4fvy42uUIYTJXrlxhyJAhBAQE0KdPH86ePcu5c+cA6NOnDzNmzMDT0/OhbSiKwr59+/jll19Yt24dzs7OLF68mLZt2xbHJeQpv5/fcmdACJEvOp2OJk2aGIcKhHgSBAQE4OHhQXh4OHv27GHDhg288MIL9O3bl+PHj7Nx48ZHBgEAjUZDx44dWblyJSdOnMDe3p727dvzwQcfkI+fuVUnYUAIkW9jxowhOzubxYsXq12KEI/txIkT+Pn50axZM06cOEGnTp0A+Oyzz1i/fj1eXl6FatfNzY39+/fz2Wef8dlnnzFt2rQSHwhkmEAIkW+ZmZlYWVnh6enJsWPH1C5HiEKLiYmhRYsWODg44O/vj42NTZH0M2fOHCZNmsRnn33G9OnTi6SPh8nv57dMCRZC5Ju5uTlNmjTh5MmT8lSBKNXeeecd9Ho9W7duLbIgAPDmm28SFxfHRx99RK9evWjevHmR9fU4ZJhACFEgo0aNIjs7myVLlqhdihCFcujQIVauXMnMmTOpXr16kff3wQcf0KRJE0aPHl1iN/ySYQIhRIHkDBV4eXlx9OhRtcsRosCeffZZoqOjOXr0KGZmZsXSZ1BQEC1btmTlypW8/PLLxdInyNMEQogiYm5uTqNGjThx4sQTs/qaKDtiY2PZvn07o0ePLrYgAODt7U2HDh1K7IZfEgaEEAWWM1SwdOlStUsRokA2btyIwWDgpZdeKva+x4wZg7+/PxEREcXe96NIGBBCFNi4cePQarX89NNPapciRIEcOXIEDw+PYpkrcC8/Pz8ADhw4UOx9P4qEASFEgZmbm+Pm5kZISAgGg0HtcoTIt7CwMNzc3FTp29bWlvr16xMSEqJK/w8jYUAIUSgjR44kOzubZcuWqV2KEPl28eJFXFxcVOvf3d2dU6dOqdZ/XiQMCCEKZdy4cWg0Gn788Ue1SxEi3xRFKdaJg/eqUKECGRkZqvWfFwkDQohCsbS0xM3NjePHj8tQgSg1LCwsSuSHsdokDAghCm3EiBFkZ2ezfPlytUsRIl9sbW2JjY1Vrf+kpCQsLS1V6z8vEgaEEIU2YcIENBoNP/zwg9qlCJEvzZo1K/RiWSkZek7HJHI8Kp7TMYmkZBR8987Q0FCaNm1aqP6LkiwsLoQoNEtLS1xdXY1DBVqt/HwhSjZvb29WrFhBWloaVlZWjzz/wo0kVgZG4R92k6i4VP67ZK8GcLSzxte1GoN8HGlQ/eF7HCQmJhIREVHo3RCLkvzLFUI8lhEjRqDX61m5cqXapQjxSF26dEGv17Np06aHnhcdl8qQXwPpNmcfywMjibwnCAAoQGRcKssDI+k2Zx9Dfg0kOi41zzZz+mzfvv1jXUNRkL0JhBCPJT09HWtra1q2bMm///6rdjlCPJKvry8Gg4GAgIAHHl8dFMVHm0+jNyhkGx75EWlkptWg02r42K8JA7wd7zverl07rKys2LlzZ6FrLyjZm0AIUSxyhgqOHj0qTxWIUmHs2LHs27ePgwcP3ndsvv8Fpm4IJUNvKFAQAMg2KGToDUzdEMp8/wu5jh0+fJiDBw8yZsyYx6q9qEgYEEI8tmHDhqHX6/n999/VLkWIR3rxxRfx8fFh1KhRpKenG19fHRTF7H/Om6SP2f+cZ01QFHB3p8/Ro0fj7e3NCy+8YJL2TU3CgBDisb3xxhtoNBrmz5+vdilCPJKZmRmLFy/m0qVLvPPOOyiKQnRcKh9tPm3Sfj7cfJrouFQ+/PBDzp8/z6JFi1Rd8Ohh5GkCIcRjs7KyokGDBgQHB8tTBaJUaNy4Md988w0TJkygYsWKXHJ+Bn0BhwUeRW9QGPjtZg5+9RVff/01Hh4eJm3flORfrBDCJHKGCtasWaN2KULky/jx4/n666/56qdlHAi/XeA5Ao+SbVC4km3DxA9mMmXKFJO2bWoSBoQQJvHmm2+i0WiYN2+e2qWIYubs7IyrqyteXl7GX6GhoQ99z5w5c7h+/XqR1rV06VL69OkDQHBwMP3797/vnClTpvD0xC9QDNmP1Vd2SgK3t87h6k+jiFk8kWtL3iDx0B9oUKjU4tnHavtBOnXqlOfjkaNHj8bf3x+A1157LV/tyTCBEMIkrK2tZaigDFuzZk2BFtOZM2cOnTp1okaNGkVX1H+0aNEiz7tW8VYOaNLyXh/gUQxZGVxfNZXybu2xf/UXNFozDFnpJIfsQEHD3vO3Ct12YSxatKjA75F/rUIIkxkyZAhZWVmsXbtW7VJECaDRaJg5cyYtW7akbt26LFmyBIBPPvmEmJgY+vfvj5eXFyEhIezevZvWrVvTrFkzmjRpwq+//mpsZ/jw4bz66qt06dKFhg0b0rdvXzIzM4G7a/33798fNzc32rdvz6uvvsrw4cPvq2Xv3r3GsHL58mUqVarERx99RLPmzTk0cxBpF4OM56ae/5erC8cS8+t44v2XED33ZfQJN/K8zpQzAWjNrajUfhAa7d0Jgtpylth6PwdA2NFD+LRqlee1jRw5kjZt2tCwYUOGDRtGWloaAKtWrcLHx4dmzZrh6enJX3/9lavf3bt34+3tjYuLC2+//TY5ywY97K5BXiQMCCFM5q233kKj0fD999+rXYooZjkf7Dm/cj7QLCwsOHLkCH///TcTJ05Er9fz4Ycf4uDgwJo1awgJCcHLy4vmzZtz4MABjh8/zv79+/nkk0+4cuWKsf2QkBD++usvzp49y40bN1i/fj1wN1hYWVlx9uxZtm3bxqFDh/JVb2JiIh4eHqzY4o9d97HE7b7703R2SgKx2+ZSre90HEbNp5x9bQxpdx7aVub1cCwc3PI8Xq6GCwvXbsvz2gIDA9mxYwdnz54lLi6O7777DoAePXrw77//cvz4cf7880/GjBmTa8fFM2fOcOjQIU6ePElAQMBjPdorYUAIYTLW1ta4uLgQFBQkCxCVMTkf7Dm/ctb9HzRoEABubm7odLo85wnExsby0ksv0bRpUzp37kxsbCynTp0yHn/++eextrbGzMyMli1bcvHiReDuT8cjRoxAo9FgY2PzwHkBD2JpaXn3DoPegIWDG/r4awBkxIRRrpoz5ezrAFDevQuYPd6IuiHtDm+OGZbntfXr1w8bGxvMzMwYNWoUu3btAuDSpUv06tWLpk2b0qdPH+Li4rh06ZLxfUOHDqVcuXJYW1szePBg4/sKQ8KAEMKkBg8eTFZWFuvWrVO7FFEC/He7XjMzM/T6B+/0N3bsWNq1a0doaCghISE0bNgw14JA+W1Ho9Hkqy4LCws0Gg3mOi1otaAUPrya13AhIyYsz+Nx23+ghU+rPK/tXjnXMGDAAEaPHs2pU6cICQmhQoUK+XpfYUgYEEKYlAwViPywtbUlMTHR+HV8fDxOTk5oNBr27dvHiRMn8tVO586dWbZsGYqikJyczB9//FGgOpzty/Pfj1ALB1eybl4mK/bubfyUU/6Q/fCtiss37oAhI4WEg78bn0owZGVwJ3jz3d+nJ+PZqEGe17Zu3TqSk5PJzs5myZIldO3aFbj7Palbty4AK1asID4+Ptf7VqxYQVZWFmlpaaxatcr4vsKQpwmEECZVoUIF6tevz5EjR+SpgjKkf//+ubYEzhn3zsvEiRMZM2YM1tbWLF26lC+//JLXX3+dTz/9FC8vL3x8fPLV74cffsioUaNo1KgRVapUwdPTk0qVKuW77vIWOupUtibq/782K18J+14TuLnhMzRm5bBybobG3AqtZfk829CWs6TGy18Sv3cpV39+Ba25JaChfOOOALj6vcqMD6Yz68uZD7w2b29vevTowa1bt2jdujVvvvkmAHPnzuXFF1+kUqVKdO7cGUfH3JsfNWrUiLZt2xIXF8dzzz3HgAED8n3d95JdC4UQJvfxxx8zY8YM1q5dy4svvqh2OeIJlpWVRXZ2NpaWlqSkpNCjRw8mTJiQ77kDADM2n2Z5YKRx0SFDRipaC2sAUs8fJj5gGbXGLChUfWZaDUN8nJjh1+SBx4cPH46Xl5cxAJia7FoohFDN22+/jUajYe7cuWqXIp5w8fHxtG3bFi8vL5566inatm1Lv379CtTGIB/HXKsPJh3dQsyv44lZ9Dp3AtdT5dnJha4v26AwuNX92xmXNHJnQAhRJFxcXIiOjiYtLU2GCkSJoigKcXFxREREcP78eb799luuNnweSydP0OT9d/Xa0jfvW6mwXBVHqvo9eKlhM62GNvXsWT4qf0MeRSG/n98yZ0AIUSQGDx7Mxx9/zKZNm+jbt6/a5QjBuHHjCAgI4PLly6SkpOQ69lSFKiS5PEWGPu+nCmoOn1Og/nRaDTOfdy9MqcVO4roQoki8/fbbwN1lZ4UoCfz9/Tl9+vR9QaBq1aoc3rWFj/MY1y+sT/yaUMfO2qRtFhUJA0KIImFjY0O9evUIDAwkH6ORQhS5ZcuWPfBZ/MWLF1OuXDkGeDsyuXtDk/Q1pbsr/b1L/lyBHBIGhBBFZtCgQWRmZrJ582a1SxFlnMFg4KeffsoVTM3MzOjUqRO9e/c2vjbetwFf9nXHQqfFTFuwRXzMtBosdFq+6uvOOF8Xk9VeHGQCoRCiyOT839GxY0f27t2rdjmijAoJCaFHjx7cvHkTFxcXzMzMCAsLQ6PRcPz4cTw9Pe97T3RcKu9tDGV/+G3MtJpcTxvcK+d4e5cqzHzevUQNDcijhUII1dna2lK3bl3+/fdftUsRZZCiKLzxxhs0b96c27dv88EHH3DhwgX++OMPdDodw4YNe2AQAKhjZ83yUT7sfLMDQ3yccLK35t77BBrAyd6aIT5O7JrUgeWjfEpUECgIuTMghChS06dPZ+bMmfz555/4+fmpXY4oI8LCwujatStXrlzB0dGRXbt20aBBA+Px8PBwHB0dMTc3z3ebKRl6LsemkKk3YK7T4mxfnvIWJfuhvPx+fksYEEIUqYSEBCpXrkynTp3w9/dXuxxRBrz33nt8+eWXwN1lj8vyEy2yzoAQokSoVKkSzs7OHD58WO1SxBMuMjKSzp07ExERQfXq1fnnn3/w8PBQu6xSQeYMCCGK3MCBA8nIyGDLli1qlyKeUDNnzqRevXpEREQwevRoYmJiJAgUgAwTCCGKXM5Qga+vL3v27FG7HPEEuXbtGl27duXMmTPY2dmxbdu2fO94WBbI0wRCiBKjUqVKODk5cejQIbVLEU+Q77//HkdHR86cOcPAgQO5deuWBIFCkjAghCgWOUMF27ZtU7sUUcrFxcXRvHlz3njjDaytrdm9ezerVq2SDbEeg3znhBDFYsqUuzu7ffPNNypXIkqzxYsXU7NmTY4fP46fnx+3b9+mc+fOapdV6snTBEKIYmFnZydDBaLQ7ty5Q69evTh06BDly5dn/fr1PPPMM2qX9cSQOwNCiGLTv39/0tPT2b59u9qliFLkjz/+oHr16hw6dIiuXbty+/ZtCQImJmFACFFs3n33XQBmz56tciWiNEhPT6dbt270798fgNWrV7Nz504sLS1VruzJI8MEQohiY2dnh6OjIwcPHlS7FFHCbdmyhQEDBpCSkkKbNm3Yvn07NjY2apf1xJI7A0KIYtWvXz/S09P5559/1C5FlECZmZn4+fnx7LPPkpWVxaJFizh48KAEgSImYUAIUaymTp0KyFCBuN+ePXuoWrUqf/31F82bN+fatWuMGjVK7bLKBAkDQohiZW9vT506dThw4IDapYgSwmAwMHDgQLp06UJqairff/89R48exc7OTu3SygwJA0KIYvfSSy+RlpbG7t271S5FqCwwMJCqVauyevVqGjduTHR0NBMmTFC7rDJHwoAQothNmzYNgK+//lrlSoRaDAYDo0ePplWrViQmJvL5559z+vRpatSooXZpZZI8TSCEKHZVqlShdu3a7N+/X+1ShApOnjxJ9+7duXHjBvXr12f37t04OTmpXVaZJncGhBCqyBkqkF0My5ZJkybh5eXFzZs3mTZtGuHh4RIESgDZwlgIoYqbN29SvXp1evToISsSlgHnz5+na9euREdHU7t2bXbt2oWrq6vaZT3xZAtjIUSJVq1aNWrVqsW+ffvULkUUsffff59GjRpx5coVJk6cSFRUlASBEkbCgBBCNTlDBXv37lW7FFEEoqKiaNCgAZ9//jlVqlTh2LFjzJ07F41Go3Zp4h4SBoQQqsl5quCrr75SuRJhal9++SX16tUjPDycESNGcO3aNby8vNQuS+RBniYQQqhGhgqePNevX6dr166cPn2aypUrs3XrVlq3bq12WeIR5M6AEEJVL7zwAqmpqQQEBKhdinhM8+fPp06dOpw+fZr+/ftz8+ZNCQKlhIQBIYSqZAGi0i8uLo4WLVowYcIErKys2LVrF6tXr0ank5vPpYWEgRJAr9eTmpqqdhlCqKJGjRo4ODjIJMJSatmyZdSsWZOjR4/Su3dvbt++TZcuXdQuSxSQhIES4PPPP8fOzo633nqL69evq12OEMWub9++pKamyuZFpUhycjLt2rVj+PDh6HQ6/vzzT7Zs2YK5ubnapYlCkDBQAty+fZvMzEy+//57nJ2dJRSIMidnqODLL79UuRKRH2vXrqVq1aocPHiQzp07c+vWLfz8/NQuSzwGCQMlhE6nIzs7m4yMDObOnUudOnXo3bs30dHRrFy5ktWrV/PPP/9w7do18rFopBClioODAzVr1pShghIuPT2d7t27069fPwBWrVrF7t27sba2Vrky8bhkdofKDAYDUVFR6PX6XK8ZDAa2bdvG559/zi+//JIrAFStWhVPT0+ee+45Bg8eTKVKlVSoXAjTev755/nxxx85ePAgbdu2VbsccY9t27bRr18/UlJSaN26Ndu3b5fl6Z8gcmdAJYqi8Ouvv9K4cWM2b95s/LDXau/+kfTu3ZugoCAWLFhARkYGSUlJhIeHs2HDBsaNG4e5uTmTJk3CwcGBYcOGceHCBTUvR4jHNn36dECGCkoavV5Pnz596N27N5mZmSxcuJBDhw5JEHjCyEZFKrh58yYjRoxg27ZtvPDCCyiKwoYNGwB47rnnmDFjRr5W6rp+/TpLly7lp59+4ubNm3z++ee88cYbmJmZFfEVCFE0atasSVJSEsnJyWqXIoC9e/fSp08fEhMT8fLyYufOnVSpUkXtskQByEZFJVRoaCgeHh4EBwezdetW1q1bx/Dhwxk8eDDHjx9n06ZN+V6ys0aNGkydOpWzZ88yduxYJk+eTOfOnUlMTCzaixCiiDz//POkpKRw+PBhtUsp0wwGA4MGDcLX15eUlBS+++47jh8/LkHgCSZ3BopRVFQUrVu3plq1amzfvp3q1aubtP19+/bx3HPP0ahRI3bs2IGNjY1J2xeiqF25coU6derg5+fHn3/+qXY5ZVJQUBC9evUiNjYWNzc3du/ejYODg9pliUKSOwMlTGpqKj179sTCwoK///7b5EEAoEOHDuzYsYPTp0/j5+dHdna2yfsQoijVrl2bGjVqsGfPHrVLKXMMBgOvvPIKLVu2JD4+nk8//ZSzZ89KECgjJAwUk6+//pqLFy+ydetWatSoUWT9tGzZks2bNxMQEMD8+fOLrB8hikqfPn1ITk4mMDBQ7VLKjFOnTlGrVi0WLlxo3Gnw/fffV7ssUYwkDBSDyMhIvvrqK9566y0aNWpU5P117NiRcePG8d5773H58uUi708IU8pZgOiLL75QuZKy4a233sLDw4MbN27wzjvvcPHiRerWrat2WaKYyZyBYjBlyhSWLFnCpUuXim0cPykpiQYNGtC3b19+/PHHYulTCFOpUaMGKSkpJCUlqV3KE+vChQt07dqVqKgoHBwc2LVrV7H8sCKKl8wZKCEMBgOrV6+mX79+xTqhz8bGhlGjRrFq1SrZBEmUOjJUULQ+/PBD3NzciI6OZvz48URHR0sQKOMkDBSxf//9lytXrjBw4MBi73vkyJEkJiaycePGYu9biMchexUUjaioKBo2bMinn36Kvb09wcHBzJs3z7jYmSi75G9AETt27BjlypWjdevWxd53/fr1ady4MYcOHSr2voV4HE5OTlSrVo3du3erXcoTY9asWdSrV48LFy4wbNgwrl+/TvPmzdUuS5QQEgaKWFhYGC4uLuh06mwD4enpyYkTJ1TpW4jH8dxzz5GUlERwcLDapZRqN2/exMPDg3feeQcbGxsOHDjA0qVL5W6AyEX+NhSxS5cuUb9+fdX6b9q0KWfOnFGtfyEKK2evAnmqoPB+/PFHatWqRWhoKC+++CK3bt2STaDEA8muhUVM7fRtZWVFVlaWqjUIURhOTk5UrVqVXbt2qV1KqZOQkEC3bt0IDg7GxsaG9evX061bN7XLEiWY3BkoYhYWFmRkZKhdhhClkp+fH3fu3OHYsWNql1Jq/Pbbb1SvXp3g4GCefvppbt++LUFAPJKEgSJWuXJlbty4Uaj3pmToOR2TyPGoeE7HJJKSoS9wGwkJCZQvX75Q/QuhtpyhgpkzZ6pcScmXnJxMhw4dGDZsGGZmZmzatImtW7dibm6udmmiFJBhgiLWvHlzFi9eTFpaGlZWVo88/8KNJFYGRuEfdpOouFT+uyKUBnC0s8bXtRqDfBxpUP3R6xacOHECDw+Pwl+AECqqW7cuVatWZefOnWqXUqKtX7+eIUOGkJaWRqdOndi6dSvW1tZqlyVKEbkzUMS8vb3Jzs5+5G3O6LhUhvwaSLc5+1geGEnkPUEAQAEi41JZHhhJtzn7GPJrINFxeS8opCgKx48fz/eWyEKURM888wx37twhJCRE7VJKnPT0dHr27MmLL76IwWBgxYoV+Pv7SxAQBSZhoIh5enpSo0YNVq1alec5q4Oi6PpdAIciYgHINjx8heic44ciYun6XQCrg6IeeN6RI0eIioqiS5cuhaxeCPXlDBV8/vnnKldSsmzfvp2qVauyY8cOfHx8uHnzJoMGDVK7LFFKSRgoYjqdjtGjR7N8+XKSk5PvOz7f/wJTN4SSoTc8MgTcK9ugkKE3MHVDKPP9L9x3fNGiRTg6OtK1a9dC1y+E2urXr0+VKlVkqOD/6fV6+vbtS69evcjIyODnn3/m33//lX1jxGORMFAMxowZQ2pqKnPnzs31+uqgKGb/c94kfcz+5zxr/nOH4PLly6xatYpRo0ZhZmZmkj6EUMszzzxDYmJimR8q2LdvH1WqVGHjxo14enoSExPDK6+8onZZ4gkgYaAYODo6MnnyZD755BPOnj0L3J0j8NHm0ybt58PNp4mOS0VRFMaOHYudnR2TJk0yaR9CqOH9998Hyu5TBQaDgcGDB9OxY0eSk5P55ptvCAkJoUqVKmqXJp4QsoVxMUlLS8PLywsbGxv8/f15/Y8zHIqILfDQwMOYaTW0qWdP64yjjBs3ji1bttC7d2+TtS+EmqpUqYJerychIUHtUopVcHAwPXv2JDY2Fjc3N3bu3Ent2rXVLkuUErKFcQljZWXFqlWruHDhAt1fHMr+8NsmDQJwdw7B/vDbvPnRl0yYMEGCgHii5AwVnDx5Uu1SioXBYOC1116jZcuWxMfH8/HHH3P27FkJAqJISBgoRk899RTbt28nwqwWGAxF0odiyKbVoCnMmTOnSNoXQi3vvfceUDaGCk6dOkXt2rVZsGABTk5OnD9/ng8//FDtssQT7IkIA87Ozri6uuLl5WX8FRoayp9//kmjRo3y/LowZsyYQXp6uvHrDz/8kJUrV+b7/a1bt8a5dW94xJ4F6ZEniZrdl5jFE4lZ9Doxi14nbvdCstP/90TCjT8+Iiv2Sq73abRmaGo1LbY9EWJiYmjfvn2x9CXKtoYNG2Jvb8+OHTsASExMxMnJidGjR3Pp0iWVqzOdyZMn4+HhwfXr15k8ebLqm52JsuGJmDPg7OzMpk2b7ltcp1evXgwdOpSBAwc+8OvC0Gg0xMfHU6lSpUK9PzlDj/uMHfctKHSv9MiTxO1eiMPIeQAYMlKJ37OIzOsXqTHsWzTavJ8Q0ACnZvSgvIUsMCmeLEOHDmX58uWEhoZibW1N/fr10Wg0aLVahg8fzvTp06lbt67aZRbKxYsX6dKlC5GRkTg4OPDPP//QpEkTtcsSpVyZnzMwceJE9u/fz3vvvUebNm3u+xogKCiIzp0706JFC5o1a8batWuN79+6dSve3t54enri5eVFYGAgY8eOBaB9+/Z4eXlx8+ZNhg8fzpw5c0hNTcXe3p7r168b25gxY4ZxNv+FCxfo3bs3rXxacvXX8dw5+leBrkdrYY1d99fJTrtDWsTd1Qyv/DiSzBsRAFxfOZW43Yu4vuJdon8cwdvvTmPbtm20a9cOZ2dnvv32W1JTUzly5AhhYWH07t0bb29vPDw8mD9/vrEfjUbDzJkzadmyJXXr1mXJkiXA3fHL8ePH06hRIzw9PXnqqadIT0/n8uXLuYLRjh07aN68OR4eHnTs2NG4ffLevXtp2rQpr7/+Op6enjRp0kT2qRcF9qC9ChRFITs7m6VLl+Li4kKfPn0IDQ3lypUrHDt2jLNnz+a6m1cSzZgxg4YNGxIVFcVrr71GdHS0BAFRvJR8SExMVAAlMTExP6cXOycnJ6Vhw4aKp6en8VdqaqrSsWNHZePGjcbz/vt1fHy84uXlpcTExCiKoii3bt1S6tSpo1y5ckUJCwtTqlatqpw9e1ZRFEXJzMxUEhISFEVRFECJj483tjls2DDlu+++UxRFUcaMGaPMmjVLURRFMRgMirOzs3Ly5ElFr9crTz31lHL27FnlWGScUuftdUq5qs5KjWHfKk5TtzzwV/WBM5Vy1ere97qVi49SqdNwxWnqFsXMtppSc8T3itPULYpFnaaKtWsbxfGdP5Xab65WKtjYKOPGjVNSUlKUhQsXKjqdTrGwsFAApVGjRsZrS0lJUdzd3ZUjR44Yr2/27NmKoijK2bNnlQoVKihZWVnKsWPHFDc3NyU7O1tRFEVJSEhQsrOzlUuXLikVK1ZUFEVRbty4odjZ2SknT55UFEVRVqxYoTRq1EgxGAyKv7+/YmZmpvz777+KoijKTz/9pHTv3t1UfwVEGWJnZ6dUrlxZOXv2rMLdVbrv+1WrVi2lVq1axq/NzMyURo0aKQMGDFDmzZunxMbGqn0ZiqIoSnR0tNKwYUMFUKpWraoEBQWpXZJ4wuT38/uJuTOwZs0aQkJCjL8etSnQoUOHiIiIoFevXnh5eRlX6QsLC2Pnzp307NkTNzc3AMqVK0fFihUfWcOIESOMP0nv3bsXe3t73N3dCQsL4/Tp0wwYMICBvTpwffkUDJlpZN2OLsSV5j3AYO3aFo3WDDPLCujMLdm5cyf29vaMGTMGvV5v3Eo5IiKCAQMG4OXlRZs2bUhKSjL+BA8YlzR1c3NDp9Nx/fp16tWrh16vZ+TIkSxbtoysrKz75iUEBgbi7u6Ou7u7sZ2YmBiuXr0KgIuLCz4+PsDduRMXL14sxPWLsq5Lly7Ex8fTunXrXK9rtVp0Oh0DBw5k7969HDt2jKNHjxIQEMCPP/6Ir68v0dHRvPXWWzg4ODB48GACAwNVugr45ptvcHZ25vz58wwdOpTr16/TokUL1eoRZVuZHVRWFIUmTZpw6NCh+47lLAxUUK1bt8ZgMHDkyBGWLl3KiBEjjH3Z2dkREhJCSoaepvmYM/DAmrP1ZN68hE2zXg88rtGZG/tLiLtNQuytB55nZmbGK6+8Qvv27WnSpMl9H+qWlpa5ztXr9VSsWJFTp04REBCAv78/06ZNY9++feh0+f8r9KB2hSiIgIAAAgICAKhYsaJxzYFy5crx2muv8e677+Lg4GA8v1q1agB06NDB+NrNmzdZtmwZv/zyCytXrmTcuHF8+eWXVKhQoViu4ebNm3Tt2pXQ0FAqVarEX3/9Rbt27YqlbyHy8sTcGSioNm3acOnSJXbt2mV8LSQkhMzMTHr06MGOHTs4d+4cAFlZWSQmJgJgY2Nj/P2DjBgxgnnz5rF161ZefvllAFxdXbG1tWXJkiWUt9DhaGdNVnwM2WlJ+a7XkJlG3M4FmFnZYlm3+UPPda5SHjdXV2rVqvXA46mpqYwbNw4PDw/MzMywsLDAwcHB+JPWggULOHr0KNnZ2cb33Lp1i5SUFLp3787MmTNxdnbOdTcBoFWrVoSGhnLq1CkAVq9eTa1atfKsQ4iC+PLLL/H19cXNzc04IapRo0ZMnDiRy5cvM3fu3FxBIC/VqlVjypQphIWFMXfuXJYsWYK7u3uxLHX8888/U7t2bUJDQ+nbty+3bt2SICBKhCcmDPTv3z/Xo4X+/v4PPb9y5cps3bqVmTNn4unpSePGjZk6dSoGgwEXFxeWLFnC4MGD8fT0xMfHh7CwMADefvttunXrZpxAeK8hQ4awevVqunbtSuXKlYG7mxVt2bKFDRs24OHhwdl5Y4jb9j2KPuOhNerjrhKzeAIxi17n+rK30OgsqDbw84c+SWCm1eDbsBrly5dn2bJlfPnll7l+evfz8yM4OJgWLVpQtWpVKlSogE6nIzU1laCgIACmTZtGixYt0Ol0xMbG0rJlSzp16kSDBg1wcHCgfv36NG7cmF69ct+hqFq1KitXrmTo0KF4eHjw008/sXbtWjQazUOvU4hHmTdvHtOmTWP69Ons2bOH3r17k5CQwPr16/MdAu6l1WqZOHEiJ0+exN7e3vjTelFISEjAx8eHsWPHYmFhwfbt21m/fn2B7qwJUZSeiEcLS5sLN5LoNmdfkbW/a1IHXKrZGL8+ceIEAwcO5OzZs7z11lt88803eb43MTGRAwcOEBgYyMmTJ7l48SLXrl0jMTHxvtv6FhYWVK5cmVq1atGgQQO8vLxo27YtLVu2xNzcvMiuT5QtGzdu5IUXXuCtt95i9uzZAJw+fZqmTZsyaNAgVqxY8dh9xMfH06VLF65cucLBgwdp0KDBY7eZY8WKFYwePZqMjAx69erFpk2b5N+HKDb5/fyWMKCSIb8GFtneBMtH+dx3LGer0169ehX6P7rk5GQOHTrE4cOHOXnyJOHh4cTExJCYmEhWVlauc83NzalUqRIODg40aNAAT09PWrduTZs2bXLNHRDiYRITE2nYsCFt2rRh/fr1uea32NnZodFoiI2NNUlfsbGxtGrViurVq7Nv377HXrgrNTWVp59+moCAAKysrFi5ciXPP/+8SWoVIr8kDJRw0XGpdPrsT6JXTr/vmJVzMyp3HlngNi10WnZN6kgdO2tTlFggaWlpHD58mMOHD3PixAkuXLhATEwMCQkJZGZm5jo35+kMBwcHXFxc8PDwoFWrVrRt27bYJnGJ0mHy5Mn89NNPhIWF3bcm/8svv8zvv//OuXPncHV1NUl/AQEBdOrUiR9++IHXX3+90O1s3LiRQYMGkZaWRseOHdm2bRvW1sX/71IICQOlwOqgKKZuMN0Y5Vd93env7Wiy9kwlMzOTI0eOcOjQIUJCQjh//jxXr14lPj7e+LhjDp1OR8WKFalZsyb169fH3d0dHx8f2rVrV+hVH0XpFBcXR82aNZk+ffoD1+XPGSoYMmQIv/32m8n6HTNmDOvXr+fq1auPfET5XpmZmfTp04e///4bCwsLFi1axODBg01WmxAFJWGglJjvf4HZ/5x/7HamdHdlnK+LCSoqXnq9nqNHj3Lw4EGOHz/O+fPniY6OJj4+/r5V48zMzLC1taVGjRrUq1cPd3d3WrZsSceOHbGzs1PpCkRRWbRoEa+++ipXr16lRo0aDzyncuXKaLVaYmNjjSsRPu6kvPPnz+Pq6srKlSuNTwTlx44dO3jxxRdJTk6mZcuW7NixQwKsUJ2EgVJkdVAUH20+jd6gFGgOgZlWg06r4RO/JiXyjsDjMhgMhISEcODAAY4dO0ZYWBjR0dHExcWRlpaW61wzMzNsbGyoXr06devWpWnTpvj4+NChQwfjs+aidMlZCOy/j//ea8CAAaxZs4Zhw4bxzz//YG5uzuXLlx+7744dO2JmZsaePXseea5er2fAgAGsX7+ecuXK8f333xuXLhdCbRIGSpnouFTe2xjK/vDbmGk1Dw0FOcfbu1Rh5vPuqswRUJvBYOD06dPs37+fY8eOce7cOaKiooiNjSU1NTXXuVqtlgoVKlC9enWcnZ1p2rQp3t7etG/fXvaGL6EURcHGxoaPPvqIKVOm3Hc8Z12B5cuXExsbi0ajQVEUnJ2dTbKD4bx585g8eTLJycmUK1cuz/MOHDjAs88+S0JCAh4eHuzcuVPCpyhR8vv5LQ+5lhB17KxZPsqHCzeSWBkYhf/5m0TFpuZaqVADONpb49uwGoNbOeZ6fLCs0Wq1uZY+/i+DwUBYWJgxKJw9e5bIyEhiYmIIDw9n586dxnM1Gg0VKlSgatWq1K1bl8aNG9OiRQs6duyIk5NTcV6S+I+rV6+SkpJiXBL8XvPmzWPOnDnGr3N+psnr/IJq1qwZmZmZnDt3Ls+/YyNGjOC3337DzMyMWbNmMXnyZJP0LYQaJAyUMA2q2zDDrwkzaEJKhp7LsSlk6g2Y67Q425eXbYnzQavV0qhRIxo1avTA4xcvXmTfvn0EBwcbg8LNmze5dOkSu3fvNp6n0WiwtramWrVqODk50ahRI5566ik6dOiAi4uLLKZUhMLDwwHyfAz2o48+4uDBgwQHBxtXytTpdCZ7qsDDwwOA0NDQ+8LA0aNH6dWrF7du3aJhw4bs3r1b7jCJUk8+WUqw8hY6mjg8eoMkUTD169enfv36xr0j/isyMpL9+/cTFBTEmTNnuHTpEjdv3iQyMpK9e/caz9NoNFhZWVG1alUcHR1xc3Pjqaeeol27djRq1Oixn1Ev63I+4PNanMfW1pZ//vmHbt26ERwcjMFgQK/Xm2yxoJzbqf+dm2IwGJgwYQI//fQTGo2Gjz76iBkzZpikPyHUJmFAiP9wcnLCycnpgY+DxcTEsH//fo4cOcLp06eJiIjgxo0bREdHs3//fhYuXGg818rKiipVqlCnTh1cXV1p3rw57du3x93dXYJCPlhYWADct0bFf9na2rJz5066devGkSNHgLzvJBREVlYWZma5l/w+c+YM3bp1IyYmBicnJ3bv3k39+vUfuy8hSgqZQCiECdy8eZP9+/cTGBjIqVOnuHTpEtevXycpKSnXhk9wd/dGe3t7ateujaurK82aNaNt27Y0a9ZM1qr/fydOnMDLy4uDBw/Spk2bh557584dnJ2diY+PJzg4mKeeeqrQ/RoMBlq3bk3FihXZuXMnv/32G6dOnWLWrFkAuZZEFqI0kKcJhCgh4uLiOHDgAP/++y+hoaFERERw/fp1EhMT7wsKFhYW2NnZUatWLVxdXY37PXh7e5epoJCRkYGNjQ3ffvst48ePf+T5OQsQLV68mBEjRhR6vs1vv/3GsGHDjF/XrFmTa9euUbNmTf755x+aNm36WNclRHGTMCBEKXDnzp1cQeHixYvG/R7u3RjK3Nz8vo2h2rRpg4+Pj/G2+pPE29ubRo0a5Xt1wcGvT8ZQvy1XDZWIinvAkzh21vi6VmOQjyMNqt//JE5KSgr169fn5s2b/Pe/xVdffZUff/xRhndEqSRhQIhSLjk52bjfw383hkpISLhvY6hy5cpRqVIlatWqhYuLi3FjqNatW5faNfHfeecdfv31V65cufLQZYFNtUbHJ598wkcffZTrfHd3d44fP37fHAIhSgsJA0I8wdLT0/n333+NG0OdP3+emJgY4uPj75t0p9PpqFSpEjVr1jRuDOXj40P79u1L9MZQFy5coGHDhvz2228MGTLkgec87uqdH/s1YYC3o3Fi4L13YwDmzJnDG2+8UejrEEJNEgaEKKMyMzMJCgrKtTHUlStX8twYytbW1rgx1H+XcS4J6+p369aNW7duERwcfN+cCVPt6zGxU11mj+jKtWvX7jtmaWnJtGnTHrhRkhClgYQBIcR99Ho9x48f5+DBgxw7dsy4MVRcXFyeG0NVr16devXq0bRpU+PGUFWqVCmWeo8cOULr1q354osveOedd4yvm3rHz7jt87CLP0fPnj1ZuHAho0eP5tNPP6Vq1aqyuJQo1SQMCCEKxGAwcPLkSfbv38/x48c5d+4c0dHRxMbG3rcxlFarzbUxVJMmTYxBIa8dBvPj/PnzhIWF8cwzzxg/hCdPnsz8+fM5cuQIHh4eRMel0vW7ADL0hse63v9RMDfTsuU1Hwb6dScrK4vg4OA8FzwSojSRMCCEMBmDwcCZM2c4cOAAR48eNW4Mdfv27Tw3hqpWrRrOzs40adIEb29vOnToQJ06dR7az9ChQ1m+fDl+fn4sXLiQatWqkZqaSrt27bhy5Qr+/v58+W8yhyJiCzRH4FHMtGAeH0n0b++wb98+mjdvbrK2hVCThAEhRLEwGAyEh4ezb98+Jk2aRHZ2Nnq9nuzsbAyG3D+9azQaypcvb9zvoXHjxsagULduXby9vQkODsbMzIyKFSuyZMkS/Pz8iI2NpXPnztxI12LZ97PHrjlh3wp09rWo0MSXhP0rMWSkYNf1Fb5ob83Ap32N5y1YsICkpCSmTJnC0qVL2bRpE5s2bSI4OJhZs2axZs0aEhISWLBgAVOnTn3suoQwNQkDQohi5+zszKZNm/Dy8jK+FhERwf79+wkODubMmTNcvnyZW7dukZycnOt5/pxtiO/Vt29ffv31VzIyMvCd/CMpDk+h0ZruUb+cMFCl2ysMbeXMDL8mDzzvv2Hgvy5fvoyXlxcJCQkmq0kIU8nv57esoiGEKFJZWVlMnz6dSZMmsXv3bl577TXatGmDXq9n9uzZNG7cmHr16uW5lsCGDRuoXLkyvr6+aMrbcWP1B1xb+iYxiyeScu4AANmpidxY/QExv44j5tfx3N46B4CMq+e4tuQNYhZPIGbR6yQd2wbA7S3fcSfoT2Mf2XduE7PyPb4e3Ytnn32W2NhYAGbMmMGbb755X0179+41Bp6xY8eSlJSEl5cXLVq0IDg4GDc3t1zBpk2bNvz999+P+60UosiUnfVNhRDFon///rk+2A8fPsysWbPo168fs2fP5ocffuDIkSNotVrs7e0JDw8nJCSElJQUvL29gbtPMuQs1VyrVi28vLyoWrM2Kzd+T7V+M9BVsCM7NZFrS9/EopYbqWcPoKtUneoDPgUgOy0JgMTDa7H16Uv5xh3vvp6e/MCa06+cxmHkfHQVKlMj7i+mTZvGL7/8kq/rXbBgAV5eXoSEhBhfs7e3Z+fOnXTv3p3jx49z69YtevbsWbBvpBDFSMKAEMKk1qxZk2uYAGDgwIH4+/vTo0cPdu/eTdWqVY3H2rRpQ6NGjfjrr7+Mr3Xr1o1atWoRHh5u3Dr6p+VrWbZ8OTf/yL1KYFbsVSxquXIn+E/idi/Csk5TrOrd3azI0smDxIOryYqLwdLJA8s6Dx4CsKrvjVmFyihAzxcGMWXssAeel19vvPEG8+fPp3v37vzwww+8/vrr8oiiKNEkDAghipxer+fUqVPY2dlx9erVB57TpUsXfv/9d4YOHcqWLVtYvnw5t2/fNh7P0hswr+JIjSEP3jWw5ojvSb8cQur5QyTsX0HNEXOx9X4OqwY+pF8OISHgN8pVdcK+x+sPrTUrW3nsD+6+ffvyzjvvcPz4cTZv3iw7HYoST+YMCCGK3NSpU3F1dWX//v1MnjyZ8PBw47HDhw9z7tw5rK2tuXLlCr6+vg/cC6CFTyv0CTdIuxxifC3zRgRKdhZZCdfRmltSvlF77LqNJSvuKkpmOlmxVyhXqQY2Xj2p2KYfmTFhD6wv7WIw2SnxAGz+YwVdu3bN97XZ2tqSlpaWaxlonU7H2LFj8fPz4/nnny8RqzkK8TByZ0AIYVL3zhn49NNP2b59O0eOHMHa2ppvv/2Wfv36cejQIeDuMMG7775LeHg49vb2ee5S6Fm/FtVe+oi4PYuJ370IDNmY2Val2gvvkxEVyq2gTaDRgiGbyr4j0VqWJ2HfctKjToJWh0arpXLnUQ9s27JOY25vnoU+KY6EVp7M+21Zvq/Xzs6OoUOH4uHhQYUKFQgODgZg1KhRvPfee/naglkItcmjhUII1eT1uF5eOs7yJzIu9dEnFpKTvTUBk30ffWI+rFu3jp9++ondu3ebpD0hCiO/n99yZ0AIUWr4ulZjeWCkSVcfzGGm1eDbsJpJ2urZsyfnz59n48aNJmlPiKImdwaEEKXGhRtJdJuzr8ja3zWpAy7VbIqsfSGKmyw6JIR44jSobkN7lyqYaU37mJ6ZVkN7lyoSBESZJWFACFGqzHzeHZ2Jw4BOq2Hm8+4mbVOI0kTCgBCiVKljZ83HeewfUFif+DWhjp21SdsUojSRMCCEKHUGeDsyuXtDk7Q1pbsr/b0dTdKWEKWVPE0ghCiVxvs2oEoFCz7afBq9QSnQEwZmWg06rYZP/JpIEBACuTMghCjFBng7smtSR9rUswd45MTCnONt6tmza1JHCQJC/D+5MyCEKNXq2FmzfJQPF24ksTIwCv/zN4mKTeW/9wk0gKO9Nb4NqzG4laM8NSDEPWSdASHEEyclQ8/l2BQy9QbMdVqc7ctT3kJ+9hFlj6xAKIQos8pb6GjiUFHtMoQoNWTOgBBCCFHGSRgQQgghyjgJA0IIIUQZJ2FACCGEKOMkDAghhBBlnIQBIYQQooyTMCCEEEKUcRIGhBBCiDJOwoAQQghRxkkYEEIIIco4CQNCCCFEGSdhQAghhCjjJAwIIYQQZZyEASGEEKKMkzAghBBClHG6/JykKAoAd+7cKdJihBBCCGE6OZ/bOZ/jeclXGEhKSgKgTp06j1mWEEIIIYpbUlISFStWzPO4RnlUXAAMBgMxMTHY2Nig0WhMWqAQQgghioaiKCQlJeHg4IBWm/fMgHyFASGEEEI8uWQCoRBCCFHGSRgQQgghyjgJA0IIIUQZJ2FACCGEKOMkDAghhBBlnIQBIYQQooyTMCCEEEKUcf8HgV/H1ZQfATAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cause</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Log_Negativity</td>\n",
       "      <td>Log_Negativity</td>\n",
       "      <td>1.861108e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coherent_Information</td>\n",
       "      <td>Coherent_Information</td>\n",
       "      <td>6.146538e+32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>3.630800e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>1.852977e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>1.892738e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>3.927095e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>1.852977e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>3.927095e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>3.622627e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Performance</td>\n",
       "      <td>-4.113345e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Performance</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>-4.113345e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Performance</td>\n",
       "      <td>Performance</td>\n",
       "      <td>5.139665e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Cause                 Effect         Score\n",
       "0          Log_Negativity         Log_Negativity  1.861108e+13\n",
       "1    Coherent_Information   Coherent_Information  6.146538e+32\n",
       "2   Entangling_Capability  Entangling_Capability  3.630800e+02\n",
       "3   Entangling_Capability         Expressibility  1.852977e-03\n",
       "4     Effective_Dimension    Effective_Dimension  1.892738e+03\n",
       "5     Effective_Dimension         Expressibility  3.927095e-03\n",
       "6          Expressibility  Entangling_Capability  1.852977e-03\n",
       "7          Expressibility    Effective_Dimension  3.927095e-03\n",
       "8          Expressibility         Expressibility  3.622627e-04\n",
       "9          Expressibility            Performance -4.113345e-03\n",
       "10            Performance         Expressibility -4.113345e-03\n",
       "11            Performance            Performance  5.139665e+02"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cdt.independence.graph import Glasso\n",
    "obj = Glasso()\n",
    "\n",
    "ugraph = obj.predict(data)\n",
    "\n",
    "nx.draw_networkx(ugraph, font_size=8) # The plot function allows for quick visualization of the graph.\n",
    "plt.show()\n",
    "# List results\n",
    "pd.DataFrame(list(ugraph.edges(data='weight')), columns=['Cause', 'Effect', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bbc8698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PC is ran on the skeleton of the given graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Execution time : 3.58 seconds ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cause</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Effective_Dimension</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Entangling_Capability</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Expressibility</td>\n",
       "      <td>Performance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Performance</td>\n",
       "      <td>Expressibility</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Cause                 Effect  Score\n",
       "0    Effective_Dimension         Expressibility      1\n",
       "1  Entangling_Capability         Expressibility      1\n",
       "2         Expressibility    Effective_Dimension      1\n",
       "3         Expressibility  Entangling_Capability      1\n",
       "4         Expressibility            Performance      1\n",
       "5            Performance         Expressibility      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cdt.causality.graph import PC\n",
    "pc = PC()\n",
    "start_time = time.time()\n",
    "dgraph = pc.orient_directed_graph(data, ugraph)\n",
    "print(\"--- Execution time : %4.4s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# Plot the output graph\n",
    "nx.draw_networkx(dgraph, font_size=8) # The plot function allows for quick visualization of the graph.\n",
    "plt.show() \n",
    "# Print output results : \n",
    "pd.DataFrame(list(dgraph.edges(data='weight')), columns=['Cause', 'Effect', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98f9910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cdt import SETTINGS\n",
    "# SETTINGS.verbose=False\n",
    "# SETTINGS.NJOBS=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "373838c0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The pairwise GNN model is computed on each edge of the UMG to initialize the model and start CGNN with a DAG\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Process Process-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-4:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Process Process-6:\n",
      "Process Process-7:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "Process Process-9:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "Process Process-15:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "Traceback (most recent call last):\n",
      "Process Process-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-8:\n",
      "Process Process-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-11:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-17:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-13:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Process Process-16:\n",
      "Process Process-14:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Mean of empty slice.\n",
      "invalid value encountered in double_scalars\n",
      "Process Process-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Process Process-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Process Process-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "Process Process-22:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "Process Process-21:\n",
      "Process Process-25:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "Traceback (most recent call last):\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-23:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-26:\n",
      "Process Process-27:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-32:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-34:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Process Process-30:\n",
      "Process Process-29:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "Process Process-31:\n",
      "Process Process-33:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "Process Process-28:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Mean of empty slice.\n",
      "invalid value encountered in double_scalars\n",
      "Process Process-37:\n",
      "Process Process-41:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-38:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-42:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "Process Process-39:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process Process-44:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Process Process-40:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-43:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "Process Process-45:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "Traceback (most recent call last):\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "Process Process-46:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "Process Process-47:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Process Process-48:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Process Process-49:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Process Process-50:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Process Process-51:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Process Process-36:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Mean of empty slice.\n",
      "invalid value encountered in double_scalars\n",
      "Process Process-53:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Process Process-57:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "Process Process-54:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Process Process-55:\n",
      "Process Process-60:\n",
      "Process Process-56:\n",
      "Process Process-58:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-65:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "Process Process-63:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "Process Process-66:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "Process Process-62:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "Process Process-61:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "Process Process-59:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "Traceback (most recent call last):\n",
      "Process Process-67:\n",
      "Traceback (most recent call last):\n",
      "Process Process-68:\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Process Process-64:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Mean of empty slice.\n",
      "invalid value encountered in double_scalars\n",
      "Process Process-70:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Process Process-71:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-72:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Process Process-76:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Process Process-75:\n",
      "Process Process-80:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-73:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Process Process-81:\n",
      "Process Process-79:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "Process Process-82:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-74:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "Process Process-83:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "Process Process-77:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-84:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "Process Process-78:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-85:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Mean of empty slice.\n",
      "invalid value encountered in double_scalars\n",
      "Process Process-87:\n",
      "Process Process-88:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Process Process-96:\n",
      "Traceback (most recent call last):\n",
      "Process Process-98:\n",
      "Process Process-89:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Process Process-91:\n",
      "Process Process-90:\n",
      "Process Process-94:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "Process Process-99:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-95:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Process Process-97:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-93:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-100:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "Process Process-101:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "Process Process-92:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "Process Process-102:\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/utils/parallel.py\", line 54, in worker_subprocess\n",
      "    output = function(*args, **kwargs, device=device, idx=idx)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/pairwise/GNN.py\", line 142, in GNN_instance\n",
      "    GNNXY = GNN_model(batch_size, nh=nh, **kwargs).to(device)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "  File \"/home/connectome/justin/.conda/envs/justin/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\n",
      "Mean of empty slice.\n",
      "invalid value encountered in double_scalars\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'networkx' has no attribute 'adj_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m Cgnn \u001b[38;5;241m=\u001b[39m CGNN(nruns\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, test_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      3\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 4\u001b[0m dgraph \u001b[38;5;241m=\u001b[39m \u001b[43mCgnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morient_undirected_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mugraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Execution time : \u001b[39m\u001b[38;5;132;01m%4.4s\u001b[39;00m\u001b[38;5;124m seconds ---\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Plot the output graph\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/graph/CGNN.py:433\u001b[0m, in \u001b[0;36mCGNN.orient_undirected_graph\u001b[0;34m(self, data, umg, alg)\u001b[0m\n\u001b[1;32m    430\u001b[0m og \u001b[38;5;241m=\u001b[39m gnn\u001b[38;5;241m.\u001b[39morient_graph(data, umg)  \u001b[38;5;66;03m# Pairwise method\u001b[39;00m\n\u001b[1;32m    431\u001b[0m dag \u001b[38;5;241m=\u001b[39m dagify_min_edge(og)\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morient_directed_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/graph/CGNN.py:398\u001b[0m, in \u001b[0;36mCGNN.orient_directed_graph\u001b[0;34m(self, data, dag, alg)\u001b[0m\n\u001b[1;32m    393\u001b[0m alg_dic \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHC\u001b[39m\u001b[38;5;124m'\u001b[39m: hill_climbing}  \u001b[38;5;66;03m# , 'HCr': hill_climbing_with_removal,\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# 'tabu': tabu_search, 'EHC': exploratory_hill_climbing}\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;66;03m# if not isinstance(data, th.utils.data.Dataset):\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m#     data = MetaDataset(data)\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malg_dic\u001b[49m\u001b[43m[\u001b[49m\u001b[43malg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnjobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnjobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnruns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnruns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtest_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdataloader_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader_workers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/justin/lib/python3.10/site-packages/cdt/causality/graph/CGNN.py:229\u001b[0m, in \u001b[0;36mhill_climbing\u001b[0;34m(data, graph, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData type not understood\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 229\u001b[0m tested_candidates \u001b[38;5;241m=\u001b[39m [\u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madj_matrix\u001b[49m(graph, nodelist\u001b[38;5;241m=\u001b[39mnodelist, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)]\n\u001b[1;32m    230\u001b[0m best_score \u001b[38;5;241m=\u001b[39m parallel_graph_evaluation(data,\n\u001b[1;32m    231\u001b[0m                                        tested_candidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtodense(),\n\u001b[1;32m    232\u001b[0m                                        \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m kwargs)\n\u001b[1;32m    233\u001b[0m best_candidate \u001b[38;5;241m=\u001b[39m graph\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'networkx' has no attribute 'adj_matrix'"
     ]
    }
   ],
   "source": [
    "# from cdt.causality.graph import CGNN\n",
    "# Cgnn = CGNN(nruns=16, train_epochs=1000, test_epochs=500, batch_size=100)\n",
    "# start_time = time.time()\n",
    "# dgraph = Cgnn.orient_undirected_graph(data, ugraph)\n",
    "# print(\"--- Execution time : %4.4s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# # Plot the output graph\n",
    "# nx.draw_networkx(dgraph, font_size=8) # The plot function allows for quick visualization of the graph.\n",
    "# plt.show() \n",
    "# # Print output results : \n",
    "# pd.DataFrame(list(dgraph.edges(data='weight')), columns=['Cause', 'Effect', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b4b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab10e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba6ff50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
